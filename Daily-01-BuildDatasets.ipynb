{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Program: Name: Daily Build Datasets\n",
    "#Purpose: Daily (Data Quality) Build Datasets for processing \n",
    "#Author:  Greg Turmel, Director, Data Governance \n",
    "#Date:    2020.08.30 - 2021.06.30\n",
    "#Errata:  0.1 Improvements can be made to script using for/looping through the databases\n",
    "\n",
    "import os, datetime\n",
    "import sqlalchemy as db\n",
    "from dotenv import load_dotenv # add this line\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import pyodbc \n",
    "import time\n",
    "\n",
    "load_dotenv() # add this line\n",
    "user = os.getenv('MySQLeUser')\n",
    "password = os.getenv('MySQLeUserPass')\n",
    "host = os.getenv('MySQLeHOST')\n",
    "db = os.getenv('MySQLeDB')\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent Directory is:  C:\\Users\\e201873842\\Documents\\Py\n",
      "Directory: Daily >>>>> Note ---- this folder already exists <<<<<\n",
      "Directory: C:\\Users\\e201873842\\Documents\\Py\\Daily\\local\\T >>>>> Note ---- this folder already exists <<<<<\n"
     ]
    }
   ],
   "source": [
    "# This segment builds the appropriatte file system structure as a variable driven exercise\n",
    "# Take time to set your 'eeeeeeeeee' number as variable 'pn' below \n",
    "# and set the program directory variable called 'programDirectory' before running\n",
    "# ===================================================================================================================\n",
    "pn = r'eeeeeeeeee'            #This represents the windows system employee login folder - IBM team uses a 9 number\n",
    "# ===================================================================================================================\n",
    "\n",
    "programDirectory = 'Daily' # Update this variable to wherever you want the program subfolder/files to be located \n",
    "un = r'C:\\Users'\n",
    "cn = r'Documents\\Py'\n",
    "tn = r'local\\T'\n",
    "\n",
    "#Set a parent directory\n",
    "parentDirectory = \"{}\\{}\\{}\".format(un,pn,cn)\n",
    "print('Parent Directory is: ', parentDirectory)\n",
    "mode = 0o666\n",
    "\n",
    "#Set path location for working with local file(s)\n",
    "path = os.path.join(parentDirectory, programDirectory,)\n",
    "pathT = os.path.join(parentDirectory, programDirectory, tn)\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path, mode)\n",
    "        print('Program Directory subfolder has been created: ', programDirectory)\n",
    "    else:\n",
    "        print('Directory:', programDirectory, '>>>>> Note ---- this folder already exists <<<<<')\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(pathT):\n",
    "        os.makedirs(pathT, mode)\n",
    "        print('Program Directory subfolder has been created: ', pathT)\n",
    "    else:\n",
    "        print('Directory:', pathT, '>>>>> Note ---- this folder already exists <<<<<')\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Collect ROW counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:10\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=ApplicationData;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count > 0\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tblRowCountAppDataWdata.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "   \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:11\n",
      " *** Note: tblRowCountAppDataWdata.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print(' *** Note: tblRowCountAppDataWdata.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:17\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Assessment;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count > 0\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tblRowCountAssmntWdata.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountAssmntWdata.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountAssmntWdata.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:18\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Control;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count > 0\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tblRowCountCtrlWdata.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountCtrlWdata.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountCtrlWdata.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:21\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=DownstreamFeeds;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count > 0\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tblRowCountDwnStrmFeedWdata.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountDwnStrmFeedWdata.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountDwnStrmFeedWdata.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:22\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=DownstreamFeeds_V1.5;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count > 0\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tblRowCountDwnStrmFeedV15Wdata.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountDwnStrmFeedV15Wdata.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountDwnStrmFeedV15Wdata.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:23\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GCPS_Operations;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count > 0\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tblRowCountGCPSOpsWdata.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountGCPSOpsWdata.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountGCPSOpsWdata.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:24\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count > 0\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tblRowCountGSDRWdata.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountGSDRWdata.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountGSDRWdata.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:26\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Synergy;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count > 0\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tblRowCountGSDRSyngyWdata.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountGSDRSyngyWdata.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountGSDRSyngyWdata.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:27\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Synergy_Temp;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count > 0\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tblRowCountGSDRSyngyTmpWdata.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountGSDRSyngyTmpWdata.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountGSDRSyngyTmpWdata.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:33\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Temp;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count > 0\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tblRowCountGSDRTmpWdata.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountGSDRTmpWdata.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountGSDRTmpWdata.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:34\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=ODS_WebApps;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count > 0\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tblRowCountODSWebAppsWdata.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountODSWebAppsWdata.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 3 seconds\n",
    "print(' *** Note: tblRowCountODSWebAppsWdata.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:36\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=PPROD;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count > 0\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tblRowCountPPdWdata.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountPPdWdata.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountPPdWdata.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:37\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Predictive_Analytics;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count > 0\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tblRowCountPrdtAnalyWdata.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountPrdtAnalyWdata.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountPrdtAnalyWdata.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Find and record where Collection has ZERO records as results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:38\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=ApplicationData;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count < 1\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tblRowCountAppDataWZero.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountAppDataWZero.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(3) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountAppDataWZero.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:42\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Assessment;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count < 1\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tblRowCountAssmntWZero.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountAssmntWZero.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountAssmntWZero.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:43\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Control;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count < 1\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tblRowCountCtrlWZero.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountCtrlWZero.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountCtrlWZero.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:44\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=DownstreamFeeds;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count < 1\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tblRowCountDwnStrmFeedWZero.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountDwnStrmFeedWZero.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountDwnStrmFeedWZero.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:45\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=DownstreamFeeds_V1.5;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count < 1\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tblRowCountDwnStrmFeedV15WZero.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountDwnStrmFeedV15WZero.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountDwnStrmFeedV15WZero.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:46\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GCPS_Operations;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count < 1\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tblRowCountGCPSOpsWZero.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountGCPSOpsWZero.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountGCPSOpsWZero.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:47\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count < 1\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tblRowCountGSDRWZero.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountGSDRWZero.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountGSDRWZero.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:48\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Synergy;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count < 1\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tblRowCountGSDRSyngyWZero.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountGSDRSyngyWZero.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountGSDRSyngyWZero.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:49\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Synergy_Temp;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count < 1\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tblRowCountGSDRSyngyTmpWZero.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountGSDRSyngyTmpWZero.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountGSDRSyngyTmpWZero.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:50\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Temp;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count < 1\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tblRowCountGSDRTmpWZero.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountGSDRTmpWZero.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountGSDRTmpWZero.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:51\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=ODS_WebApps;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count < 1\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tblRowCountODSWebAppsWZero.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountODSWebAppsWZero.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountODSWebAppsWZero.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:52\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=PPROD;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count < 1\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tblRowCountPPdWZero.csv'), 'w') as f:\n",
    "        df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "        \n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountPPdWZero.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountPPdWZero.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:53\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Predictive_Analytics;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count < 1\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tblRowCountPrdtAnalyWZero.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountPrdtAnalyWZero.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountPrdtAnalyWZero.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collection (original) file format for winmerge analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:55\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=ApplicationData;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tableRowCountApplicationData.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableRowCountApplicationData.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableRowCountApplicationData.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Collect (T) daily and overwrite existing name (Todays data used for loading Greg(DB) tables for automation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:56\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Assessment;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tableRowCountAssessment.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep=',', index=False, encoding='cp1252', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableRowCountAssessment.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableRowCountAssessment.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Collect (T) daily and overwrite existing name (Todays data used for loading Greg(DB) tables for automation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:57\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Control;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tableRowCountControl.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep=',', index=False, encoding='cp1252', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableRowCountControl.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableRowCountControl.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Collect (T) daily and overwrite existing name (Todays data used for loading Greg(DB) tables for automation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:58\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=DownstreamFeeds;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tableRowCountDownstreamFeeds.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep=',', index=False, encoding='cp1252', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableRowCountDownstreamFeeds.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableRowCountDownstreamFeeds.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Collect (T) daily and overwrite existing name (Todays data used for loading Greg(DB) tables for automation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:17:59\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=DownstreamFeeds_V1.5;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tableRowCountDownstreamFeedsV15.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep=',', index=False, encoding='cp1252', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableRowCountDownstreamFeedsV15.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableRowCountDownstreamFeedsV15.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Collect (T) daily and overwrite existing name (Todays data used for loading Greg(DB) tables for automation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:00\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GCPS_Operations;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tableRowCountGCPS_Operations.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep=',', index=False, encoding='cp1252', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableRowCountGCPS_Operations.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableRowCountGCPS_Operations.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Collect (T) daily and overwrite existing name (Todays data used for loading Greg(DB) tables for automation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:01\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Synergy_Temp;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tableRowCountGSDR_Synergy_Temp.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep=',', index=False, encoding='cp1252', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableRowCountGSDR_Synergy_Temp.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableRowCountGSDR_Synergy_Temp.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Collect (T) daily and overwrite existing name (Todays data used for loading Greg(DB) tables for automation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:02\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Synergy;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tableRowCountGSDR_Synergy.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep=',', index=False, encoding='cp1252', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableRowCountGSDR_Synergy.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableRowCountGSDR_Synergy.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Collect (T) daily and overwrite existing name (Todays data used for loading Greg(DB) tables for automation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:03\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Temp;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tableRowCountGSDR_Temp.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep=',', index=False, encoding='cp1252', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableRowCountGSDR_Temp.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableRowCountGSDR_Temp.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Collect (T) daily and overwrite existing name (Todays data used for loading Greg(DB) tables for automation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:04\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tableRowCountGSDR.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep=',', index=False, encoding='cp1252', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableRowCountGSDR.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableRowCountGSDR.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Collect (T) daily and overwrite existing name (Todays data used for loading Greg(DB) tables for automation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:05\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=ODS_WebApps;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tableRowCountODS_WebApps.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep=',', index=False, encoding='cp1252', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableRowCountODS_WebApps.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableRowCountODS_WebApps.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Collect (T) daily and overwrite existing name (Todays data used for loading Greg(DB) tables for automation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:06\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=PPROD;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tableRowCountPPROD.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep=',', index=False, encoding='cp1252', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableRowCountPPROD.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableRowCountPPROD.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Collect (T) daily and overwrite existing name (Todays data used for loading Greg(DB) tables for automation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:07\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Predictive_Analytics;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tableRowCountPredictive_Analytics.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep=',', index=False, encoding='cp1252', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableRowCountPredictive_Analytics.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableRowCountPredictive_Analytics.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(002) Collect data sets that include the query text that can be captured in the past 24 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:09\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=master;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "\t, DB_NAME(database_id) AS DatabaseName\n",
    "\t, OBJECT_SCHEMA_NAME(ps.object_id, database_id) AS SchemaName\n",
    "\t, OBJECT_NAME(ps.object_id, database_id) AS ObjectName\n",
    "\t, ps.last_execution_time AS LastProcLastExecutionTime\n",
    "\t, qs.last_execution_time AS LastQueryExecutionTime\n",
    "\t, SUBSTRING(st.text, (qs.statement_start_offset/2) + 1,\n",
    "\t \t  ((CASE statement_end_offset \n",
    "\t \t\t  WHEN -1 THEN DATALENGTH(ST.text)\n",
    "\t \t\t  ELSE qs.statement_end_offset END \n",
    "\t \t\t\t  - qs.statement_start_offset)/2) + 1) AS proc_query_text\n",
    "\t, ps.total_logical_reads AS ProcLastTotalReads\n",
    "\t, ps.total_worker_time AS ProcTotalWorkerTime\n",
    "\t, ps.total_elapsed_time AS ProcTotalElapsedTime\n",
    "\t, qs.total_logical_reads AS QueryTotalLogicalReads\n",
    "\t, qs.total_worker_time AS QueryTotalWorkerTime\n",
    "\t, qs.total_elapsed_time AS QueryTotalElapsedTime\n",
    "FROM sys.dm_exec_procedure_stats AS ps\n",
    "JOIN sys.dm_exec_query_stats AS qs ON\n",
    "\tqs.sql_handle = ps.sql_handle\n",
    "CROSS APPLY sys.dm_exec_sql_text(qs.sql_handle) as st\n",
    "--- WHERE\n",
    "--- \tobject_id = OBJECT_ID(N'YourDatabase.dbo.sp_1')\n",
    "WHERE DB_NAME(database_id) IS NOT NULL --- AND DB_NAME(database_id) in (msdb, master, model, tempdb)\n",
    "ORDER BY\n",
    "\t DatabaseName\n",
    "\t,SchemaName\n",
    "\t,ObjectName\n",
    "\t,ps.sql_handle\n",
    "\t,qs.statement_start_offset\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'tableLastRunwSQLtextStatement.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableLastRunwSQLtextStatement.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableLastRunwSQLtextStatement.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(003) Collection of details by Chris Lanzi from production and stored daily in the development (Greg) database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:17\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=DEVODSSQL;'\n",
    "                      'Database=GREG;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT [run_date]\n",
    "      ,[database_name]\n",
    "      ,[schema_name]\n",
    "      ,[table_name]\n",
    "  FROM [Greg].[dbo].[Tables_Unused_Since_Last_Restart]\n",
    "  Order by run_date desc\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'TablesUsedSinceRunDate-LastUsedTableList.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: TablesUsedSinceRunDateLastUsedTableList.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: TablesUsedSinceRunDateLastUsedTableList.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(004) Find and collect all table column position precision details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:19\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=ApplicationData;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, IS_NULLABLE, DATA_TYPE\n",
    "from INFORMATION_SCHEMA.COLUMNS\n",
    "Order by TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION;\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findTabColPosPrecDetailsApplicationData.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findTabColPosPrecDetailsApplicationData.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findTabColPosPrecDetailsApplicationData.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:21\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Assessment;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, IS_NULLABLE, DATA_TYPE\n",
    "from INFORMATION_SCHEMA.COLUMNS\n",
    "Order by TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION;\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findTabColPosPrecDetailsAssessment.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findTabColPosPrecDetailsAssessment.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findTabColPosPrecDetailsAssessment.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:23\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Control;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, IS_NULLABLE, DATA_TYPE\n",
    "from INFORMATION_SCHEMA.COLUMNS\n",
    "Order by TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION;\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findTabColPosPrecDetailsControl.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findTabColPosPrecDetailsControl.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findTabColPosPrecDetailsControl.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:24\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=DownstreamFeeds;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, IS_NULLABLE, DATA_TYPE\n",
    "from INFORMATION_SCHEMA.COLUMNS\n",
    "Order by TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION;\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findTabColPosPrecDetailsDownstreamFeeds.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findTabColPosPrecDetailsDownstreamFeeds.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findTabColPosPrecDetailsDownstreamFeeds.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:25\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=DownstreamFeeds_V1.5;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, IS_NULLABLE, DATA_TYPE\n",
    "from INFORMATION_SCHEMA.COLUMNS\n",
    "Order by TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION;\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findTabColPosPrecDetailsDownstreamFeeds_V15.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findTabColPosPrecDetailsDownstreamFeeds_V15.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findTabColPosPrecDetailsDownstreamFeeds_V15.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:27\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GCPS_Operations;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, IS_NULLABLE, DATA_TYPE\n",
    "from INFORMATION_SCHEMA.COLUMNS\n",
    "Order by TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION;\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findTabColPosPrecDetailsGCPS_Operations.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findTabColPosPrecDetailsGCPS_Operations.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findTabColPosPrecDetailsGCPS_Operations.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:28\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Synergy_Temp;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, IS_NULLABLE, DATA_TYPE\n",
    "from INFORMATION_SCHEMA.COLUMNS\n",
    "Order by TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION;\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findTabColPosPrecDetailsGSDR_Synergy_Temp.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findTabColPosPrecDetailsGSDR_Synergy_Temp.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findTabColPosPrecDetailsGSDR_Synergy_Temp.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:29\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Synergy;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, IS_NULLABLE, DATA_TYPE\n",
    "from INFORMATION_SCHEMA.COLUMNS\n",
    "Order by TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION;\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findTabColPosPrecDetailsGSDR_Synergy.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findTabColPosPrecDetailsGSDR_Synergy.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findTabColPosPrecDetailsGSDR_Synergy.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:31\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Temp;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, IS_NULLABLE, DATA_TYPE\n",
    "from INFORMATION_SCHEMA.COLUMNS\n",
    "Order by TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION;\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findTabColPosPrecDetailsGSDR_Temp.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findTabColPosPrecDetailsGSDR_Temp.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findTabColPosPrecDetailsGSDR_Temp.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:33\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, IS_NULLABLE, DATA_TYPE\n",
    "from INFORMATION_SCHEMA.COLUMNS\n",
    "Order by TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION;\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findTabColPosPrecDetailsGSDR.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findTabColPosPrecDetailsGSDR.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findTabColPosPrecDetailsGSDR.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:34\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=ODS_WebApps;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, IS_NULLABLE, DATA_TYPE\n",
    "from INFORMATION_SCHEMA.COLUMNS\n",
    "Order by TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION;\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findTabColPosPrecDetailsODS_WebApps.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findTabColPosPrecDetailsODS_WebApps.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findTabColPosPrecDetailsODS_WebApps.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:36\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=PPROD;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, IS_NULLABLE, DATA_TYPE\n",
    "from INFORMATION_SCHEMA.COLUMNS\n",
    "Order by TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION;\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findTabColPosPrecDetailsPPROD.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findTabColPosPrecDetailsPPROD.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findTabColPosPrecDetailsPPROD.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:37\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Predictive_Analytics;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, IS_NULLABLE, DATA_TYPE\n",
    "from INFORMATION_SCHEMA.COLUMNS\n",
    "Order by TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION;\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findTabColPosPrecDetailsPredictive_Analytics.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findTabColPosPrecDetailsPredictive_Analytics.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findTabColPosPrecDetailsPredictive_Analytics.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(006) Collect and catalog details about what was last modified over the past 7 days (change to 360 to see a year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:38\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=ApplicationData;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "# Control collection with statement\n",
    "# WHERE modify_date > GETDATE() - 360\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "  ,name AS object_name   \n",
    "  ,SCHEMA_NAME(schema_id) AS schema_name  \n",
    "  ,type_desc  \n",
    "  ,create_date  \n",
    "  ,modify_date  \n",
    "FROM sys.objects  \n",
    "WHERE modify_date > GETDATE() - 7\n",
    "ORDER BY modify_date DESC, object_name;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findCrModObjinLast360ApplicationData.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findCrModObjinLast360ApplicationData.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findCrModObjinLast360ApplicationData.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:39\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Assessment;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "  ,name AS object_name   \n",
    "  ,SCHEMA_NAME(schema_id) AS schema_name  \n",
    "  ,type_desc  \n",
    "  ,create_date  \n",
    "  ,modify_date  \n",
    "FROM sys.objects  \n",
    "WHERE modify_date > GETDATE() - 8\n",
    "ORDER BY modify_date DESC, object_name;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findCrModObjinLast360Assessment.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findCrModObjinLast360Assessment.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findCrModObjinLast360Assessment.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:40\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Control;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "  ,name AS object_name   \n",
    "  ,SCHEMA_NAME(schema_id) AS schema_name  \n",
    "  ,type_desc  \n",
    "  ,create_date  \n",
    "  ,modify_date  \n",
    "FROM sys.objects  \n",
    "WHERE modify_date > GETDATE() - 8\n",
    "ORDER BY modify_date DESC, object_name;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findCrModObjinLast360Control.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findCrModObjinLast360Control.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findCrModObjinLast360Control.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:41\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=DownstreamFeeds;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "  ,name AS object_name   \n",
    "  ,SCHEMA_NAME(schema_id) AS schema_name  \n",
    "  ,type_desc  \n",
    "  ,create_date  \n",
    "  ,modify_date  \n",
    "FROM sys.objects  \n",
    "WHERE modify_date > GETDATE() - 8\n",
    "ORDER BY modify_date DESC, object_name;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findCrModObjinLast360DownstreamFeeds.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findCrModObjinLast360DownstreamFeeds.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findCrModObjinLast360DownstreamFeeds.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:42\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=DownstreamFeeds_V1.5;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "  ,name AS object_name   \n",
    "  ,SCHEMA_NAME(schema_id) AS schema_name  \n",
    "  ,type_desc  \n",
    "  ,create_date  \n",
    "  ,modify_date  \n",
    "FROM sys.objects  \n",
    "WHERE modify_date > GETDATE() - 8\n",
    "ORDER BY modify_date DESC, object_name;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findCrModObjinLast360DownstreamFeeds_V1.5.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findCrModObjinLast360DownstreamFeeds_V1.5.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findCrModObjinLast360DownstreamFeeds_V1.5.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:43\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GCPS_Operations;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "  ,name AS object_name   \n",
    "  ,SCHEMA_NAME(schema_id) AS schema_name  \n",
    "  ,type_desc  \n",
    "  ,create_date  \n",
    "  ,modify_date  \n",
    "FROM sys.objects  \n",
    "WHERE modify_date > GETDATE() - 10\n",
    "ORDER BY modify_date DESC, object_name;  \n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findCrModObjinLast360GCPS_Operations.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findCrModObjinLast360GCPS_Operations.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findCrModObjinLast360GCPS_Operations.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:44\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Synergy_Temp;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "  ,name AS object_name   \n",
    "  ,SCHEMA_NAME(schema_id) AS schema_name  \n",
    "  ,type_desc  \n",
    "  ,create_date  \n",
    "  ,modify_date  \n",
    "FROM sys.objects  \n",
    "WHERE modify_date > GETDATE() - 10\n",
    "ORDER BY modify_date DESC, object_name;   \n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findCrModObjinLast360GSDR_Synergy_Temp.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findCrModObjinLast360GSDR_Synergy_Temp.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findCrModObjinLast360GSDR_Synergy_Temp.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:45\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Synergy;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "  ,name AS object_name   \n",
    "  ,SCHEMA_NAME(schema_id) AS schema_name  \n",
    "  ,type_desc  \n",
    "  ,create_date  \n",
    "  ,modify_date  \n",
    "FROM sys.objects  \n",
    "WHERE modify_date > GETDATE() - 10\n",
    "ORDER BY modify_date DESC, object_name;   \n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findCrModObjinLast360GSDR_Synergy.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findCrModObjinLast360GSDR_Synergy.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findCrModObjinLast360GSDR_Synergy.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:47\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Temp;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "  ,name AS object_name   \n",
    "  ,SCHEMA_NAME(schema_id) AS schema_name  \n",
    "  ,type_desc  \n",
    "  ,create_date  \n",
    "  ,modify_date  \n",
    "FROM sys.objects  \n",
    "WHERE modify_date > GETDATE() - 8\n",
    "ORDER BY modify_date DESC, object_name;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findCrModObjinLast360GSDR_Temp.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findCrModObjinLast360GSDR_Temp.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findCrModObjinLast360GSDR_Temp.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:48\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "  ,name AS object_name   \n",
    "  ,SCHEMA_NAME(schema_id) AS schema_name  \n",
    "  ,type_desc  \n",
    "  ,create_date  \n",
    "  ,modify_date  \n",
    "FROM sys.objects  \n",
    "WHERE modify_date > GETDATE() - 8\n",
    "ORDER BY modify_date DESC, object_name;   \n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findCrModObjinLast360GSDR.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findCrModObjinLast360GSDR.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findCrModObjinLast360GSDR.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:49\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=ODS_WebApps;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "  ,name AS object_name   \n",
    "  ,SCHEMA_NAME(schema_id) AS schema_name  \n",
    "  ,type_desc  \n",
    "  ,create_date  \n",
    "  ,modify_date  \n",
    "FROM sys.objects  \n",
    "WHERE modify_date > GETDATE() - 8\n",
    "ORDER BY modify_date DESC, object_name;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findCrModObjinLast360ODS_WebApps.csv'), 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:49\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=PPROD;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "  ,name AS object_name   \n",
    "  ,SCHEMA_NAME(schema_id) AS schema_name  \n",
    "  ,type_desc  \n",
    "  ,create_date  \n",
    "  ,modify_date  \n",
    "FROM sys.objects  \n",
    "WHERE modify_date > GETDATE() - 8\n",
    "ORDER BY modify_date DESC, object_name;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findCrModObjinLast360PPROD.csv'), 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findCrModObjinLast360PPROD.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findCrModObjinLast360PPROD.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:50\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Predictive_Analytics;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "  ,name AS object_name   \n",
    "  ,SCHEMA_NAME(schema_id) AS schema_name  \n",
    "  ,type_desc  \n",
    "  ,create_date  \n",
    "  ,modify_date  \n",
    "FROM sys.objects  \n",
    "WHERE modify_date > GETDATE() - 8\n",
    "ORDER BY modify_date DESC, object_name;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findCrModObjinLast360Predictive_Analytics.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findCrModObjinLast360Predictive_Analytics.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findCrModObjinLast360Predictive_Analytics.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(007) Capture and catalog all stored procedures (current) in the database(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:51\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=ApplicationData;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "       SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_TYPE, CREATED, LAST_ALTERED\n",
    " FROM [ApplicationData].INFORMATION_SCHEMA.ROUTINES\n",
    " WHERE ROUTINE_TYPE = 'PROCEDURE' \n",
    "   AND LEFT(ROUTINE_NAME, 3) NOT IN ('xp_', 'ms_')\n",
    " Order by LAST_ALTERED Desc;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'ProceduresApplicationData.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: ProceduresApplicationData.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: ProceduresApplicationData.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:52\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Assessment;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "       SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_TYPE, CREATED, LAST_ALTERED\n",
    "  FROM [Assessment].INFORMATION_SCHEMA.ROUTINES\n",
    " WHERE ROUTINE_TYPE = 'PROCEDURE' \n",
    "   AND LEFT(ROUTINE_NAME, 3) NOT IN ('xp_', 'ms_')\n",
    " Order by LAST_ALTERED Desc;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'ProceduresAssessment.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: ProceduresAssessment.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: ProceduresAssessment.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:53\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Control;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "       SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_TYPE, CREATED, LAST_ALTERED\n",
    "  FROM [Control].INFORMATION_SCHEMA.ROUTINES\n",
    " WHERE ROUTINE_TYPE = 'PROCEDURE' \n",
    "   AND LEFT(ROUTINE_NAME, 3) NOT IN ('xp_', 'ms_')\n",
    " Order by LAST_ALTERED Desc;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'ProceduresControl.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: ProceduresControl.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: ProceduresControl.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:54\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=DownstreamFeeds;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "       SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_TYPE, CREATED, LAST_ALTERED\n",
    "  FROM [DownstreamFeeds].INFORMATION_SCHEMA.ROUTINES\n",
    " WHERE ROUTINE_TYPE = 'PROCEDURE' \n",
    "   AND LEFT(ROUTINE_NAME, 3) NOT IN ('xp_', 'ms_')\n",
    " Order by LAST_ALTERED Desc;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'ProceduresDownstreamFeeds.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: ProceduresDownstreamFeeds.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: ProceduresDownstreamFeeds.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:55\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=DownstreamFeeds_V1.5;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "       SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_TYPE, CREATED, LAST_ALTERED\n",
    "  FROM [DownstreamFeeds_V1.5].INFORMATION_SCHEMA.ROUTINES\n",
    " WHERE ROUTINE_TYPE = 'PROCEDURE' \n",
    "   AND LEFT(ROUTINE_NAME, 3) NOT IN ('xp_', 'ms_')\n",
    " Order by LAST_ALTERED Desc;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'ProceduresDownstreamFeeds_V15.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: ProceduresDownstreamFeeds_V15.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: ProceduresDownstreamFeeds_V15.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:56\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GCPS_Operations;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "       SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_TYPE, CREATED, LAST_ALTERED\n",
    "  FROM [GCPS_Operations].INFORMATION_SCHEMA.ROUTINES\n",
    " WHERE ROUTINE_TYPE = 'PROCEDURE' \n",
    "   AND LEFT(ROUTINE_NAME, 3) NOT IN ('xp_', 'ms_')\n",
    " Order by LAST_ALTERED Desc;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'ProceduresGCPS_Operations.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: ProceduresGCPS_Operations.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: ProceduresGCPS_Operations.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:57\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Synergy_Temp;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "       SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_TYPE, CREATED, LAST_ALTERED\n",
    "  FROM [GSDR_Synergy_Temp].INFORMATION_SCHEMA.ROUTINES\n",
    " WHERE ROUTINE_TYPE = 'PROCEDURE' \n",
    "   AND LEFT(ROUTINE_NAME, 3) NOT IN ('xp_', 'ms_')\n",
    " Order by LAST_ALTERED Desc;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'ProceduresGSDR_Synergy_Temp.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: ProceduresGSDR_Synergy_Temp.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: ProceduresGSDR_Synergy_Temp.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:18:58\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Synergy;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "       SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_TYPE, CREATED, LAST_ALTERED\n",
    "  FROM [GSDR_Synergy].INFORMATION_SCHEMA.ROUTINES\n",
    " WHERE ROUTINE_TYPE = 'PROCEDURE' \n",
    "   AND LEFT(ROUTINE_NAME, 3) NOT IN ('xp_', 'ms_')\n",
    " Order by LAST_ALTERED Desc;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'ProceduresGSDR_Synergy.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: ProceduresGSDR_Synergy.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: ProceduresGSDR_Synergy.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:19:00\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Temp;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "       SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_TYPE, CREATED, LAST_ALTERED\n",
    "  FROM [GSDR_Temp].INFORMATION_SCHEMA.ROUTINES\n",
    " WHERE ROUTINE_TYPE = 'PROCEDURE' \n",
    "   AND LEFT(ROUTINE_NAME, 3) NOT IN ('xp_', 'ms_')\n",
    " Order by LAST_ALTERED Desc;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'ProceduresGSDR_Temp.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: ProceduresGSDR_Temp.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: ProceduresGSDR_Temp.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:19:01\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "       SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_TYPE, CREATED, LAST_ALTERED\n",
    "  FROM [GSDR].INFORMATION_SCHEMA.ROUTINES\n",
    " WHERE ROUTINE_TYPE = 'PROCEDURE' \n",
    "   AND LEFT(ROUTINE_NAME, 3) NOT IN ('xp_', 'ms_')\n",
    " Order by LAST_ALTERED Desc;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'ProceduresGSDR.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: ProceduresGSDR.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: ProceduresGSDR.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:19:02\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=ODS_WebApps;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "       SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_TYPE, CREATED, LAST_ALTERED\n",
    "  FROM [ODS_WebApps].INFORMATION_SCHEMA.ROUTINES\n",
    " WHERE ROUTINE_TYPE = 'PROCEDURE' \n",
    "   AND LEFT(ROUTINE_NAME, 3) NOT IN ('xp_', 'ms_')\n",
    " Order by LAST_ALTERED Desc;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'ProceduresODS_WebApps.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: ProceduresODS_WebApps.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: ProceduresODS_WebApps.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:19:03\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=PPROD;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "       SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_TYPE, CREATED, LAST_ALTERED\n",
    "  FROM [PPROD].INFORMATION_SCHEMA.ROUTINES\n",
    " WHERE ROUTINE_TYPE = 'PROCEDURE' \n",
    "   AND LEFT(ROUTINE_NAME, 3) NOT IN ('xp_', 'ms_')\n",
    " Order by LAST_ALTERED Desc;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'ProceduresPPROD.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: ProceduresPPROD.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: ProceduresPPROD.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:19:05\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Predictive_Analytics;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "       SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_TYPE, CREATED, LAST_ALTERED\n",
    "  FROM [Predictive_Analytics].INFORMATION_SCHEMA.ROUTINES\n",
    " WHERE ROUTINE_TYPE = 'PROCEDURE' \n",
    "   AND LEFT(ROUTINE_NAME, 3) NOT IN ('xp_', 'ms_')\n",
    " Order by LAST_ALTERED Desc;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'ProceduresPredictive_Analytics.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: ProceduresPredictive_Analytics.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: ProceduresPredictive_Analytics.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(008) Find and collect all registered DTSX packages in the database (validate against TFS code repository) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:19:06\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Master;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    ",  J.name AS JobName \n",
    ",  S.step_id AS StepNbr\n",
    ",  S.step_name AS StepName\n",
    ",  LEFT(REPLACE(REPLACE(S.command, '/FILE \"',''),'\\\"',''), CHARINDEX('.dtsx', REPLACE(REPLACE(S.command, '/FILE \"',''),'\\\"',''))+4) AS SSISPackagePath\n",
    "FROM  msdb.dbo.sysjobs AS J\n",
    "INNER JOIN msdb.dbo.sysjobsteps AS S \n",
    "ON  J.job_id = S.job_id\n",
    "WHERE J.enabled = 1 \n",
    "AND  S.subsystem = 'SSIS'\n",
    "ORDER BY J.name \n",
    ",  S.step_id;\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findtopJobNameStepNum_dtsx.csv'), 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findtopJobNameStepNum_dtsx.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findtopJobNameStepNum_dtsx.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(009) Find all the current SSMS job failures and review for changes to the system for EDP migration effort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:19:07\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Master;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "# The furthest back SQL Server will retain errata on the job runs is day, 120\n",
    "# change the declare statement back if the results you are seeking are not in the retained file records\n",
    "# looking at run status = 1 (success) results in nothing tangible for the migration effort \n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "declare @date datetime = dateadd(hour, 12, datediff(day, 7, getdate()));\n",
    "\n",
    "/* PRODODSSQL */\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "select \n",
    "    [sJobHistory].[server]\n",
    "  , [sJOB].[name] as          [JobName]\n",
    "  , [sJobHistory].step_id\n",
    "  , [sJobHistory].step_name\n",
    "  , case\n",
    "\t\twhen [sJobHistory].run_status = 1 then 'Succeeded'\n",
    "\t\twhen [sJobHistory].run_status = 0 then 'Failed'\n",
    "\t\telse convert(nvarchar(10),[sJobHistory].run_status)\n",
    "\tend\trun_status \n",
    "  , sJobHistory.[message]\n",
    "  , [msdb].[dbo].agent_datetime(run_date,run_time) runtime\n",
    "  , [sJobHistory].run_duration\n",
    "  , [sJOB].[description] as   [JobDescription]\n",
    "\n",
    "from [msdb].[dbo].[sysjobs]\t\t\t\t\t\tas [sJOB]\n",
    "join [msdb].[dbo].[sysjobhistory]\t\t\t\tas [sJobHistory]\ton [sjob].job_id\t\t\t\t\t= sJobHistory.job_id\n",
    "left join [msdb].[sys].[servers]\t\t\t\tas [sSVR]\t\t\ton [sJOB].[originating_server_id]\t= [sSVR].[server_id]\n",
    "left join [msdb].[dbo].[syscategories]\t\t\tas [sCAT]\t\t\ton [sJOB].[category_id]\t\t\t\t= [sCAT].[category_id]\n",
    "left join [msdb].[dbo].[sysjobsteps]\t\t\tas [sJSTP]\t\t\ton [sJOB].[job_id]\t\t\t\t\t= [sJSTP].[job_id]\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tand [sJOB].[start_step_id]\t\t\t= [sJSTP].[step_id]\n",
    "left join [msdb].[sys].[database_principals]\tas [sDBP]\t\t\ton [sJOB].[owner_sid]\t\t\t\t= [sDBP].[sid]\n",
    "left join [msdb].[dbo].[sysjobschedules]\t\tas [sJOBSCH]\t\ton [sJOB].[job_id]\t\t\t\t\t= [sJOBSCH].[job_id]\n",
    "left join [msdb].[dbo].[sysschedules]\t\t\tas [sSCH]\t\t\ton [sJOBSCH].[schedule_id]\t\t\t= [sSCH].[schedule_id]\n",
    "\n",
    "where 1=1\n",
    "\n",
    "and run_status = 0\n",
    "\n",
    "and [msdb].[dbo].agent_datetime(run_date,run_time) >= @date\n",
    "\n",
    "\n",
    "/* PRODSISSQL */\n",
    "union all\n",
    "select \n",
    "    [sJobHistory].[server]\n",
    "  , [sJOB].[name] as          [JobName]\n",
    "  , [sJobHistory].step_id\n",
    "  , [sJobHistory].step_name\n",
    "  , case\n",
    "\t\twhen [sJobHistory].run_status = 1 then 'Succeeded'\n",
    "\t\twhen [sJobHistory].run_status = 0 then 'Failed'\n",
    "\t\telse convert(nvarchar(10),[sJobHistory].run_status)\n",
    "\tend\trun_status \n",
    "  , sJobHistory.[message]\n",
    "  , [msdb].[dbo].agent_datetime(run_date,run_time) runtime\n",
    "  , [sJobHistory].run_duration\n",
    "  , [sJOB].[description] as   [JobDescription]\n",
    "\n",
    "from prodsissql.[msdb].[dbo].[sysjobs]\t\t\t\t\t\tas [sJOB]\n",
    "join prodsissql.[msdb].[dbo].[sysjobhistory]\t\t\t\tas [sJobHistory]\ton [sjob].job_id\t\t\t\t\t= sJobHistory.job_id\n",
    "left join prodsissql.[msdb].[sys].[servers]\t\t\t\t\tas [sSVR]\t\t\ton [sJOB].[originating_server_id]\t= [sSVR].[server_id]\n",
    "left join prodsissql.[msdb].[dbo].[syscategories]\t\t\tas [sCAT]\t\t\ton [sJOB].[category_id]\t\t\t\t= [sCAT].[category_id]\n",
    "left join prodsissql.[msdb].[dbo].[sysjobsteps]\t\t\t\tas [sJSTP]\t\t\ton [sJOB].[job_id]\t\t\t\t\t= [sJSTP].[job_id]\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tand [sJOB].[start_step_id]\t\t\t= [sJSTP].[step_id]\n",
    "left join prodsissql.[msdb].[sys].[database_principals]\t\tas [sDBP]\t\t\ton [sJOB].[owner_sid]\t\t\t\t= [sDBP].[sid]\n",
    "left join prodsissql.[msdb].[dbo].[sysjobschedules]\t\t\tas [sJOBSCH]\t\ton [sJOB].[job_id]\t\t\t\t\t= [sJOBSCH].[job_id]\n",
    "left join prodsissql.[msdb].[dbo].[sysschedules]\t\t\tas [sSCH]\t\t\ton [sJOBSCH].[schedule_id]\t\t\t= [sSCH].[schedule_id]\n",
    "\n",
    "where 1=1\n",
    "\n",
    "and run_status = 0\n",
    "and [msdb].[dbo].agent_datetime(run_date,run_time) >= @date\n",
    "\n",
    "order by \n",
    "runtime desc\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findSSMSjobFailures.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findSSMSjobFailures.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findSSMSjobFailures.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(010) Collection of table differences compared to partitions found (looking for uniqueness) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:19:08\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "c.name as SchemaName, t.name as TableName, t.object_id as TableObjectID, s.object_id as PartObjectID, s.row_count as RecordCount\n",
    "from sys.tables t,\n",
    "sys.dm_db_partition_stats s,\n",
    "sys.schemas c\n",
    "where \n",
    "t.schema_id = c.schema_id\n",
    "AND t.object_id = s.object_id\n",
    "AND t.type_desc = 'USER_TABLE'\n",
    "AND t.name not like '%dss%'\n",
    "AND s.index_id IN (0,1)\n",
    "ORDER BY 2\n",
    "\n",
    "                              '''\n",
    "                              ,conn) \n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(os.path.join(pathT, 'findGSDRtablePartitioningDiffObjectsIDS.csv'), 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findGSDRtablePartitioningDiffObjectsIDS.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findGSDRtablePartitioningDiffObjectsIDS.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-06-14 07:19:09\n",
      " *** Note: ****.csv files written - this program has completed successfully - review output ***\n"
     ]
    }
   ],
   "source": [
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print(' *** Note: ****.csv files written - this program has completed successfully - review output ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
