{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Program: Name: Daily (Data Quality) Audit Run2-Merge-AB-testing-Local-C\n",
    "#Purpose: Daily (Data Quality) Run for collecting details about system changes and merging-AB into Local-C\n",
    "#Author:  Greg Turmel, Director, Data Governance \n",
    "#Date:    2020.08.30 - 2021.06.30\n",
    "#Errata:  0.1 Improvements can be made to script using for/looping through the databases\n",
    "\n",
    "import os, datetime\n",
    "import sqlalchemy as db\n",
    "from dotenv import load_dotenv # add this line\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import pyodbc \n",
    "import time\n",
    "load_dotenv() # add this line\n",
    "user = os.getenv('MySQLeUser')\n",
    "password = os.getenv('MySQLeUserPass')\n",
    "host = os.getenv('MySQLeHOST')\n",
    "db = os.getenv('MySQLeDB')\n",
    "%matplotlib inline\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Collect ROW counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=ApplicationData;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count > 0\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tblRowCountAppDataWdata.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tblRowCountAppDataWdata.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tblRowCountAppDataWdata.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:02:49\n",
      " *** Note: tblRowCountAppDataWdata.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print(' *** Note: tblRowCountAppDataWdata.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open(\"thefile.csv\", \"w\") as f:\n",
    "    df.to_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#outfile = open(path+'filename.csv', 'wb')\n",
    "#df.to_csv(outfile)\n",
    "#outfile.close()     # this is an older method since Python 3 will auto-close open files after written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:02:53\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Assessment;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count > 0\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tblRowCountAssmntWdata.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tblRowCountAssmntWdata.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tblRowCountAssmntWdata.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountAssmntWdata.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountAssmntWdata.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:02:55\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Control;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count > 0\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tblRowCountCtrlWdata.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tblRowCountCtrlWdata.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tblRowCountCtrlWdata.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountCtrlWdata.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountCtrlWdata.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:02:59\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=DownstreamFeeds;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count > 0\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tblRowCountDwnStrmFeedWdata.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tblRowCountDwnStrmFeedWdata.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tblRowCountDwnStrmFeedWdata.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountDwnStrmFeedWdata.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountDwnStrmFeedWdata.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:00\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=DownstreamFeeds_V1.5;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count > 0\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tblRowCountDwnStrmFeedV15Wdata.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tblRowCountDwnStrmFeedV15Wdata.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tblRowCountDwnStrmFeedV15Wdata.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountDwnStrmFeedV15Wdata.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountDwnStrmFeedV15Wdata.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:01\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GCPS_Operations;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count > 0\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tblRowCountGCPSOpsWdata.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tblRowCountGCPSOpsWdata.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tblRowCountGCPSOpsWdata.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountGCPSOpsWdata.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountGCPSOpsWdata.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:03\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count > 0\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tblRowCountGSDRWdata.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tblRowCountGSDRWdata.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tblRowCountGSDRWdata.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountGSDRWdata.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountGSDRWdata.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:06\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Synergy;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count > 0\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tblRowCountGSDRSyngyWdata.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tblRowCountGSDRSyngyWdata.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tblRowCountGSDRSyngyWdata.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountGSDRSyngyWdata.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountGSDRSyngyWdata.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:08\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Synergy_Temp;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count > 0\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tblRowCountGSDRSyngyTmpWdata.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tblRowCountGSDRSyngyTmpWdata.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tblRowCountGSDRSyngyTmpWdata.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountGSDRSyngyTmpWdata.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountGSDRSyngyTmpWdata.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:15\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Temp;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count > 0\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tblRowCountGSDRTmpWdata.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tblRowCountGSDRTmpWdata.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tblRowCountGSDRTmpWdata.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountGSDRTmpWdata.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountGSDRTmpWdata.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:17\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=ODS_WebApps;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count > 0\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tblRowCountODSWebAppsWdata.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tblRowCountODSWebAppsWdata.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tblRowCountODSWebAppsWdata.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountODSWebAppsWdata.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 3 seconds\n",
    "print(' *** Note: tblRowCountODSWebAppsWdata.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:18\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=PPROD;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count > 0\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tblRowCountPPdWdata.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tblRowCountPPdWdata.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tblRowCountPPdWdata.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountPPdWdata.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountPPdWdata.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:20\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Predictive_Analytics;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count > 0\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tblRowCountPrdtAnalyWdata.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tblRowCountPrdtAnalyWdata.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tblRowCountPrdtAnalyWdata.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountPrdtAnalyWdata.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountPrdtAnalyWdata.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Find and record where Collection has ZERO records as results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:21\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=ApplicationData;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count < 1\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tblRowCountAppDataWZero.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tblRowCountAppDataWZero.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tblRowCountAppDataWZero.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountAppDataWZero.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(3) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountAppDataWZero.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:25\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Assessment;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count < 1\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tblRowCountAssmntWZero.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tblRowCountAssmntWZero.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tblRowCountAssmntWZero.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountAssmntWZero.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountAssmntWZero.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:26\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Control;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count < 1\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tblRowCountCtrlWZero.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tblRowCountCtrlWZero.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tblRowCountCtrlWZero.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountCtrlWZero.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountCtrlWZero.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:28\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=DownstreamFeeds;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count < 1\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tblRowCountDwnStrmFeedWZero.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tblRowCountDwnStrmFeedWZero.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tblRowCountDwnStrmFeedWZero.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountDwnStrmFeedWZero.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountDwnStrmFeedWZero.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:29\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=DownstreamFeeds_V1.5;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count < 1\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tblRowCountDwnStrmFeedV15WZero.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tblRowCountDwnStrmFeedV15WZero.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tblRowCountDwnStrmFeedV15WZero.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountDwnStrmFeedV15WZero.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountDwnStrmFeedV15WZero.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:30\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GCPS_Operations;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count < 1\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tblRowCountGCPSOpsWZero.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tblRowCountGCPSOpsWZero.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tblRowCountGCPSOpsWZero.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountGCPSOpsWZero.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountGCPSOpsWZero.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:32\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count < 1\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tblRowCountGSDRWZero.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tblRowCountGSDRWZero.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tblRowCountGSDRWZero.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountGSDRWZero.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountGSDRWZero.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:34\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Synergy;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count < 1\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tblRowCountGSDRSyngyWZero.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tblRowCountGSDRSyngyWZero.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tblRowCountGSDRSyngyWZero.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountGSDRSyngyWZero.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountGSDRSyngyWZero.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:35\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Synergy_Temp;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count < 1\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tblRowCountGSDRSyngyTmpWZero.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tblRowCountGSDRSyngyTmpWZero.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tblRowCountGSDRSyngyTmpWZero.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountGSDRSyngyTmpWZero.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountGSDRSyngyTmpWZero.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:37\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Temp;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count < 1\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tblRowCountGSDRTmpWZero.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tblRowCountGSDRTmpWZero.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tblRowCountGSDRTmpWZero.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountGSDRTmpWZero.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountGSDRTmpWZero.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:38\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=ODS_WebApps;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count < 1\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tblRowCountODSWebAppsWZero.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tblRowCountODSWebAppsWZero.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tblRowCountODSWebAppsWZero.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountODSWebAppsWZero.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountODSWebAppsWZero.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:39\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=PPROD;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count < 1\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tblRowCountPPdWZero.csv', 'a') as f:\n",
    "        df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tblRowCountPPdWZero.csv', 'a') as f:\n",
    "        df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tblRowCountPPdWZero.csv', 'w') as f:\n",
    "        df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "        \n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountPPdWZero.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountPPdWZero.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:41\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Predictive_Analytics;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "AND p.row_count < 1\n",
    "ORDER BY TableName\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tblRowCountPrdtAnalyWZero.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tblRowCountPrdtAnalyWZero.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tblRowCountPrdtAnalyWZero.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tblRowCountPrdtAnalyWZero.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tblRowCountPrdtAnalyWZero.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collection (original) file format for winmerge analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:42\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=ApplicationData;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tableRowCountApplicationData.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tableRowCountApplicationData.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tableRowCountApplicationData.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableRowCountApplicationData.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableRowCountApplicationData.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:44\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Assessment;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tableRowCountAssessment.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tableRowCountAssessment.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, line_terminator='\\n')\n",
    "\n",
    "#with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tableRowCountAssessment.csv', 'w') as f:\n",
    "    #df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Collect (T) daily and overwrite existing name (Todays data used for loading Greg(DB) tables for automation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:45\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Assessment;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tableRowCountAssessment.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep=',', index=False, encoding='cp1252', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableRowCountAssessment.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableRowCountAssessment.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:46\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Control;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tableRowCountControl.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tableRowCountControl.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, line_terminator='\\n')\n",
    "\n",
    "#with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tableRowCountControl.csv', 'w') as f:\n",
    "    #df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Collect (T) daily and overwrite existing name (Todays data used for loading Greg(DB) tables for automation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:46\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Control;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tableRowCountControl.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep=',', index=False, encoding='cp1252', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableRowCountControl.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableRowCountControl.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:47\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=DownstreamFeeds;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tableRowCountDownstreamFeeds.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tableRowCountDownstreamFeeds.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, line_terminator='\\n')\n",
    "\n",
    "#with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tableRowCountDownstreamFeeds.csv', 'w') as f:\n",
    "    #df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, encoding='utf-8', line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Collect (T) daily and overwrite existing name (Todays data used for loading Greg(DB) tables for automation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:47\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=DownstreamFeeds;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tableRowCountDownstreamFeeds.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep=',', index=False, encoding='cp1252', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableRowCountDownstreamFeeds.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableRowCountDownstreamFeeds.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:48\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=DownstreamFeeds_V1.5;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tableRowCountDownstreamFeedsV15.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tableRowCountDownstreamFeedsV15.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, line_terminator='\\n')\n",
    "\n",
    "#with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tableRowCountDownstreamFeedsV15.csv', 'w') as f:\n",
    "    #df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Collect (T) daily and overwrite existing name (Todays data used for loading Greg(DB) tables for automation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:48\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=DownstreamFeeds_V1.5;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tableRowCountDownstreamFeedsV15.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep=',', index=False, encoding='cp1252', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableRowCountDownstreamFeedsV15.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableRowCountDownstreamFeedsV15.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:49\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GCPS_Operations;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tableRowCountGCPS_Operations.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tableRowCountGCPS_Operations.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, line_terminator='\\n')\n",
    "\n",
    "#with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tableRowCountGCPS_Operations.csv', 'w') as f:\n",
    "    #df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Collect (T) daily and overwrite existing name (Todays data used for loading Greg(DB) tables for automation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:49\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GCPS_Operations;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tableRowCountGCPS_Operations.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep=',', index=False, encoding='cp1252', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableRowCountGCPS_Operations.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableRowCountGCPS_Operations.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:51\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Synergy_Temp;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tableRowCountGSDR_Synergy_Temp.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tableRowCountGSDR_Synergy_Temp.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, line_terminator='\\n')\n",
    "\n",
    "#with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tableRowCountGSDR_Synergy_Temp.csv', 'w') as f:\n",
    "    #df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Collect (T) daily and overwrite existing name (Todays data used for loading Greg(DB) tables for automation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:51\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Synergy_Temp;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tableRowCountGSDR_Synergy_Temp.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep=',', index=False, encoding='cp1252', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableRowCountGSDR_Synergy_Temp.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableRowCountGSDR_Synergy_Temp.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:52\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Synergy;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tableRowCountGSDR_Synergy.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tableRowCountGSDR_Synergy.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, line_terminator='\\n')\n",
    "\n",
    "#with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tableRowCountGSDR_Synergy.csv', 'w') as f:\n",
    "    #df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Collect (T) daily and overwrite existing name (Todays data used for loading Greg(DB) tables for automation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:52\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Synergy;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tableRowCountGSDR_Synergy.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep=',', index=False, encoding='cp1252', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableRowCountGSDR_Synergy.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableRowCountGSDR_Synergy.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:53\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Temp;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tableRowCountGSDR_Temp.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tableRowCountGSDR_Temp.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, line_terminator='\\n')\n",
    "\n",
    "#with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tableRowCountGSDR_Temp.csv', 'w') as f:\n",
    "    #df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Collect (T) daily and overwrite existing name (Todays data used for loading Greg(DB) tables for automation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:53\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Temp;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tableRowCountGSDR_Temp.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep=',', index=False, encoding='cp1252', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableRowCountGSDR_Temp.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableRowCountGSDR_Temp.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:54\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tableRowCountGSDR.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tableRowCountGSDR.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, line_terminator='\\n')\n",
    "\n",
    "#with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tableRowCountGSDR.csv', 'w') as f:\n",
    "    #df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Collect (T) daily and overwrite existing name (Todays data used for loading Greg(DB) tables for automation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:54\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tableRowCountGSDR.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep=',', index=False, encoding='cp1252', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableRowCountGSDR.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableRowCountGSDR.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:56\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=ODS_WebApps;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tableRowCountODS_WebApps.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tableRowCountODS_WebApps.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, line_terminator='\\n')\n",
    "\n",
    "#with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tableRowCountODS_WebApps.csv', 'w') as f:\n",
    "    #df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Collect (T) daily and overwrite existing name (Todays data used for loading Greg(DB) tables for automation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:56\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=ODS_WebApps;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tableRowCountODS_WebApps.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep=',', index=False, encoding='cp1252', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableRowCountODS_WebApps.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableRowCountODS_WebApps.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:57\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=PPROD;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tableRowCountPPROD.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tableRowCountPPROD.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, line_terminator='\\n')\n",
    "\n",
    "#with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tableRowCountPPROD.csv', 'w') as f:\n",
    "    #df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Collect (T) daily and overwrite existing name (Todays data used for loading Greg(DB) tables for automation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:57\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=PPROD;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tableRowCountPPROD.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep=',', index=False, encoding='cp1252', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableRowCountPPROD.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableRowCountPPROD.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:58\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Predictive_Analytics;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tableRowCountPredictive_Analytics.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tableRowCountPredictive_Analytics.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, line_terminator='\\n')\n",
    "\n",
    "#with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tableRowCountPredictive_Analytics.csv', 'w') as f:\n",
    "    #df.to_csv(f, header=f.tell()==0, sep='\\t', index=False, encoding='utf-8', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Collect (T) daily and overwrite existing name (Todays data used for loading Greg(DB) tables for automation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:58\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Predictive_Analytics;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, p.row_count as RecordCount\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s\n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "WHERE o.type LIKE 'U'\n",
    "ORDER BY TableName\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tableRowCountPredictive_Analytics.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, sep=',', index=False, encoding='cp1252', line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableRowCountPredictive_Analytics.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableRowCountPredictive_Analytics.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(002) Collect data sets that include the query text that can be captured in the past 24 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:03:59\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=master;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "\t, DB_NAME(database_id) AS DatabaseName\n",
    "\t, OBJECT_SCHEMA_NAME(ps.object_id, database_id) AS SchemaName\n",
    "\t, OBJECT_NAME(ps.object_id, database_id) AS ObjectName\n",
    "\t, ps.last_execution_time AS LastProcLastExecutionTime\n",
    "\t, qs.last_execution_time AS LastQueryExecutionTime\n",
    "\t, SUBSTRING(st.text, (qs.statement_start_offset/2) + 1,\n",
    "\t \t  ((CASE statement_end_offset \n",
    "\t \t\t  WHEN -1 THEN DATALENGTH(ST.text)\n",
    "\t \t\t  ELSE qs.statement_end_offset END \n",
    "\t \t\t\t  - qs.statement_start_offset)/2) + 1) AS proc_query_text\n",
    "\t, ps.total_logical_reads AS ProcLastTotalReads\n",
    "\t, ps.total_worker_time AS ProcTotalWorkerTime\n",
    "\t, ps.total_elapsed_time AS ProcTotalElapsedTime\n",
    "\t, qs.total_logical_reads AS QueryTotalLogicalReads\n",
    "\t, qs.total_worker_time AS QueryTotalWorkerTime\n",
    "\t, qs.total_elapsed_time AS QueryTotalElapsedTime\n",
    "FROM sys.dm_exec_procedure_stats AS ps\n",
    "JOIN sys.dm_exec_query_stats AS qs ON\n",
    "\tqs.sql_handle = ps.sql_handle\n",
    "CROSS APPLY sys.dm_exec_sql_text(qs.sql_handle) as st\n",
    "--- WHERE\n",
    "--- \tobject_id = OBJECT_ID(N'YourDatabase.dbo.sp_1')\n",
    "WHERE DB_NAME(database_id) IS NOT NULL --- AND DB_NAME(database_id) in (msdb, master, model, tempdb)\n",
    "ORDER BY\n",
    "\t DatabaseName\n",
    "\t,SchemaName\n",
    "\t,ObjectName\n",
    "\t,ps.sql_handle\n",
    "\t,qs.statement_start_offset\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\tableLastRunwSQLtextStatement.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\tableLastRunwSQLtextStatement.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\tableLastRunwSQLtextStatement.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: tableLastRunwSQLtextStatement.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: tableLastRunwSQLtextStatement.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(003) Collection of details by Chris Lanzi from production and stored daily in the development (Greg) database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:15\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=DEVODSSQL;'\n",
    "                      'Database=GREG;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT [run_date]\n",
    "      ,[database_name]\n",
    "      ,[schema_name]\n",
    "      ,[table_name]\n",
    "  FROM [Greg].[dbo].[Tables_Unused_Since_Last_Restart]\n",
    "  Order by run_date desc\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "df.to_csv (r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\TablesUsedSinceRunDate-LastUsedTableList.csv', sep='\\t', index = False) \n",
    "\n",
    "df.to_csv (r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\TablesUsedSinceRunDate-LastUsedTableList.csv', sep='\\t', index = False) \n",
    "\n",
    "df.to_csv (r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\TablesUsedSinceRunDate-LastUsedTableList.csv', sep='\\t', index = False) \n",
    "\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: TablesUsedSinceRunDateLastUsedTableList.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: TablesUsedSinceRunDateLastUsedTableList.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(004) Find and collect all table column position precision details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:16\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=ApplicationData;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, IS_NULLABLE, DATA_TYPE\n",
    "from INFORMATION_SCHEMA.COLUMNS\n",
    "Order by TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION;\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findTabColPosPrecDetailsApplicationData.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findTabColPosPrecDetailsApplicationData.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findTabColPosPrecDetailsApplicationData.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findTabColPosPrecDetailsApplicationData.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findTabColPosPrecDetailsApplicationData.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:19\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Assessment;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, IS_NULLABLE, DATA_TYPE\n",
    "from INFORMATION_SCHEMA.COLUMNS\n",
    "Order by TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION;\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findTabColPosPrecDetailsAssessment.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findTabColPosPrecDetailsAssessment.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findTabColPosPrecDetailsAssessment.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findTabColPosPrecDetailsAssessment.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findTabColPosPrecDetailsAssessment.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:20\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Control;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, IS_NULLABLE, DATA_TYPE\n",
    "from INFORMATION_SCHEMA.COLUMNS\n",
    "Order by TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION;\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findTabColPosPrecDetailsControl.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findTabColPosPrecDetailsControl.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findTabColPosPrecDetailsControl.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findTabColPosPrecDetailsControl.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findTabColPosPrecDetailsControl.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:22\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=DownstreamFeeds;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, IS_NULLABLE, DATA_TYPE\n",
    "from INFORMATION_SCHEMA.COLUMNS\n",
    "Order by TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION;\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findTabColPosPrecDetailsDownstreamFeeds.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findTabColPosPrecDetailsDownstreamFeeds.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findTabColPosPrecDetailsDownstreamFeeds.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findTabColPosPrecDetailsDownstreamFeeds.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findTabColPosPrecDetailsDownstreamFeeds.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:24\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=DownstreamFeeds_V1.5;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, IS_NULLABLE, DATA_TYPE\n",
    "from INFORMATION_SCHEMA.COLUMNS\n",
    "Order by TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION;\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findTabColPosPrecDetailsDownstreamFeeds_V15.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findTabColPosPrecDetailsDownstreamFeeds_V15.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findTabColPosPrecDetailsDownstreamFeeds_V15.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findTabColPosPrecDetailsDownstreamFeeds_V15.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findTabColPosPrecDetailsDownstreamFeeds_V15.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:25\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GCPS_Operations;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, IS_NULLABLE, DATA_TYPE\n",
    "from INFORMATION_SCHEMA.COLUMNS\n",
    "Order by TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION;\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findTabColPosPrecDetailsGCPS_Operations.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findTabColPosPrecDetailsGCPS_Operations.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findTabColPosPrecDetailsGCPS_Operations.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findTabColPosPrecDetailsGCPS_Operations.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findTabColPosPrecDetailsGCPS_Operations.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:26\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Synergy_Temp;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, IS_NULLABLE, DATA_TYPE\n",
    "from INFORMATION_SCHEMA.COLUMNS\n",
    "Order by TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION;\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findTabColPosPrecDetailsGSDR_Synergy_Temp.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findTabColPosPrecDetailsGSDR_Synergy_Temp.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findTabColPosPrecDetailsGSDR_Synergy_Temp.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findTabColPosPrecDetailsGSDR_Synergy_Temp.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findTabColPosPrecDetailsGSDR_Synergy_Temp.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:28\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Synergy;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, IS_NULLABLE, DATA_TYPE\n",
    "from INFORMATION_SCHEMA.COLUMNS\n",
    "Order by TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION;\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findTabColPosPrecDetailsGSDR_Synergy.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findTabColPosPrecDetailsGSDR_Synergy.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findTabColPosPrecDetailsGSDR_Synergy.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findTabColPosPrecDetailsGSDR_Synergy.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findTabColPosPrecDetailsGSDR_Synergy.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:30\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Temp;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, IS_NULLABLE, DATA_TYPE\n",
    "from INFORMATION_SCHEMA.COLUMNS\n",
    "Order by TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION;\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findTabColPosPrecDetailsGSDR_Temp.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findTabColPosPrecDetailsGSDR_Temp.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findTabColPosPrecDetailsGSDR_Temp.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findTabColPosPrecDetailsGSDR_Temp.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findTabColPosPrecDetailsGSDR_Temp.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:33\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, IS_NULLABLE, DATA_TYPE\n",
    "from INFORMATION_SCHEMA.COLUMNS\n",
    "Order by TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION;\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findTabColPosPrecDetailsGSDR.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findTabColPosPrecDetailsGSDR.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findTabColPosPrecDetailsGSDR.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findTabColPosPrecDetailsGSDR.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findTabColPosPrecDetailsGSDR.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:34\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=ODS_WebApps;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, IS_NULLABLE, DATA_TYPE\n",
    "from INFORMATION_SCHEMA.COLUMNS\n",
    "Order by TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION;\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findTabColPosPrecDetailsODS_WebApps.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findTabColPosPrecDetailsODS_WebApps.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findTabColPosPrecDetailsODS_WebApps.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findTabColPosPrecDetailsODS_WebApps.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findTabColPosPrecDetailsODS_WebApps.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:36\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=PPROD;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, IS_NULLABLE, DATA_TYPE\n",
    "from INFORMATION_SCHEMA.COLUMNS\n",
    "Order by TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION;\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findTabColPosPrecDetailsPPROD.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findTabColPosPrecDetailsPPROD.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findTabColPosPrecDetailsPPROD.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findTabColPosPrecDetailsPPROD.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findTabColPosPrecDetailsPPROD.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:38\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Predictive_Analytics;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, IS_NULLABLE, DATA_TYPE\n",
    "from INFORMATION_SCHEMA.COLUMNS\n",
    "Order by TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, ORDINAL_POSITION;\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findTabColPosPrecDetailsPredictive_Analytics.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findTabColPosPrecDetailsPredictive_Analytics.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findTabColPosPrecDetailsPredictive_Analytics.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findTabColPosPrecDetailsPredictive_Analytics.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findTabColPosPrecDetailsPredictive_Analytics.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(005) Collection activities that are only about the table column and position details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Synergy;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "       TABLE_CATALOG ,\n",
    "\t   TABLE_SCHEMA ,\n",
    "       TABLE_NAME ,\n",
    "       COLUMN_NAME ,\n",
    "       ORDINAL_POSITION ,\n",
    "       COLUMN_DEFAULT ,\n",
    "       DATA_TYPE ,\n",
    "       CHARACTER_MAXIMUM_LENGTH ,\n",
    "       NUMERIC_PRECISION ,\n",
    "       NUMERIC_PRECISION_RADIX ,\n",
    "       NUMERIC_SCALE ,\n",
    "       DATETIME_PRECISION\n",
    "FROM   INFORMATION_SCHEMA.COLUMNS\n",
    "where table_name in (select name from sys.tables)\n",
    "order by TABLE_SCHEMA ,\n",
    "TABLE_NAME ,\n",
    "ORDINAL_POSITION;\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findTabColPosDetailsGSDR_Synergy.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findTabColPosDetailsGSDR_Synergy.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findTabColPosDetailsGSDR_Synergy.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findTabColPosDetailsGSDR_Synergy.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(006) Collect and catalog details about what was last modified over the past 7 days (change to 360 to see a year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:39\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=ApplicationData;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "# Control collection with statement\n",
    "# WHERE modify_date > GETDATE() - 360\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "  ,name AS object_name   \n",
    "  ,SCHEMA_NAME(schema_id) AS schema_name  \n",
    "  ,type_desc  \n",
    "  ,create_date  \n",
    "  ,modify_date  \n",
    "FROM sys.objects  \n",
    "WHERE modify_date > GETDATE() - 7\n",
    "ORDER BY modify_date DESC, object_name;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findCrModObjinLast360ApplicationData.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findCrModObjinLast360ApplicationData.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findCrModObjinLast360ApplicationData.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findCrModObjinLast360ApplicationData.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findCrModObjinLast360ApplicationData.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:40\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Assessment;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "  ,name AS object_name   \n",
    "  ,SCHEMA_NAME(schema_id) AS schema_name  \n",
    "  ,type_desc  \n",
    "  ,create_date  \n",
    "  ,modify_date  \n",
    "FROM sys.objects  \n",
    "WHERE modify_date > GETDATE() - 8\n",
    "ORDER BY modify_date DESC, object_name;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findCrModObjinLast360Assessment.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findCrModObjinLast360Assessment.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findCrModObjinLast360Assessment.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findCrModObjinLast360Assessment.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findCrModObjinLast360Assessment.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:41\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Control;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "  ,name AS object_name   \n",
    "  ,SCHEMA_NAME(schema_id) AS schema_name  \n",
    "  ,type_desc  \n",
    "  ,create_date  \n",
    "  ,modify_date  \n",
    "FROM sys.objects  \n",
    "WHERE modify_date > GETDATE() - 8\n",
    "ORDER BY modify_date DESC, object_name;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findCrModObjinLast360Control.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findCrModObjinLast360Control.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findCrModObjinLast360Control.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findCrModObjinLast360Control.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findCrModObjinLast360Control.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:42\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=DownstreamFeeds;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "  ,name AS object_name   \n",
    "  ,SCHEMA_NAME(schema_id) AS schema_name  \n",
    "  ,type_desc  \n",
    "  ,create_date  \n",
    "  ,modify_date  \n",
    "FROM sys.objects  \n",
    "WHERE modify_date > GETDATE() - 8\n",
    "ORDER BY modify_date DESC, object_name;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findCrModObjinLast360DownstreamFeeds.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findCrModObjinLast360DownstreamFeeds.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findCrModObjinLast360DownstreamFeeds.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findCrModObjinLast360DownstreamFeeds.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findCrModObjinLast360DownstreamFeeds.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:43\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=DownstreamFeeds_V1.5;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "  ,name AS object_name   \n",
    "  ,SCHEMA_NAME(schema_id) AS schema_name  \n",
    "  ,type_desc  \n",
    "  ,create_date  \n",
    "  ,modify_date  \n",
    "FROM sys.objects  \n",
    "WHERE modify_date > GETDATE() - 8\n",
    "ORDER BY modify_date DESC, object_name;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findCrModObjinLast360DownstreamFeeds_V1.5.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findCrModObjinLast360DownstreamFeeds_V1.5.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findCrModObjinLast360DownstreamFeeds_V1.5.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findCrModObjinLast360DownstreamFeeds_V1.5.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findCrModObjinLast360DownstreamFeeds_V1.5.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:44\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GCPS_Operations;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "  ,name AS object_name   \n",
    "  ,SCHEMA_NAME(schema_id) AS schema_name  \n",
    "  ,type_desc  \n",
    "  ,create_date  \n",
    "  ,modify_date  \n",
    "FROM sys.objects  \n",
    "WHERE modify_date > GETDATE() - 10\n",
    "ORDER BY modify_date DESC, object_name;  \n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findCrModObjinLast360GCPS_Operations.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findCrModObjinLast360GCPS_Operations.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findCrModObjinLast360GCPS_Operations.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findCrModObjinLast360GCPS_Operations.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findCrModObjinLast360GCPS_Operations.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:45\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Synergy_Temp;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "  ,name AS object_name   \n",
    "  ,SCHEMA_NAME(schema_id) AS schema_name  \n",
    "  ,type_desc  \n",
    "  ,create_date  \n",
    "  ,modify_date  \n",
    "FROM sys.objects  \n",
    "WHERE modify_date > GETDATE() - 10\n",
    "ORDER BY modify_date DESC, object_name;   \n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findCrModObjinLast360GSDR_Synergy_Temp.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findCrModObjinLast360GSDR_Synergy_Temp.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findCrModObjinLast360GSDR_Synergy_Temp.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findCrModObjinLast360GSDR_Synergy_Temp.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findCrModObjinLast360GSDR_Synergy_Temp.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:47\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Synergy;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "  ,name AS object_name   \n",
    "  ,SCHEMA_NAME(schema_id) AS schema_name  \n",
    "  ,type_desc  \n",
    "  ,create_date  \n",
    "  ,modify_date  \n",
    "FROM sys.objects  \n",
    "WHERE modify_date > GETDATE() - 10\n",
    "ORDER BY modify_date DESC, object_name;   \n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findCrModObjinLast360GSDR_Synergy.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findCrModObjinLast360GSDR_Synergy.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findCrModObjinLast360GSDR_Synergy.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findCrModObjinLast360GSDR_Synergy.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findCrModObjinLast360GSDR_Synergy.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:48\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Temp;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "  ,name AS object_name   \n",
    "  ,SCHEMA_NAME(schema_id) AS schema_name  \n",
    "  ,type_desc  \n",
    "  ,create_date  \n",
    "  ,modify_date  \n",
    "FROM sys.objects  \n",
    "WHERE modify_date > GETDATE() - 8\n",
    "ORDER BY modify_date DESC, object_name;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findCrModObjinLast360GSDR_Temp.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findCrModObjinLast360GSDR_Temp.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findCrModObjinLast360GSDR_Temp.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findCrModObjinLast360GSDR_Temp.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findCrModObjinLast360GSDR_Temp.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:49\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "  ,name AS object_name   \n",
    "  ,SCHEMA_NAME(schema_id) AS schema_name  \n",
    "  ,type_desc  \n",
    "  ,create_date  \n",
    "  ,modify_date  \n",
    "FROM sys.objects  \n",
    "WHERE modify_date > GETDATE() - 8\n",
    "ORDER BY modify_date DESC, object_name;   \n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findCrModObjinLast360GSDR.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findCrModObjinLast360GSDR.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findCrModObjinLast360GSDR.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findCrModObjinLast360GSDR.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findCrModObjinLast360GSDR.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:50\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=ODS_WebApps;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "  ,name AS object_name   \n",
    "  ,SCHEMA_NAME(schema_id) AS schema_name  \n",
    "  ,type_desc  \n",
    "  ,create_date  \n",
    "  ,modify_date  \n",
    "FROM sys.objects  \n",
    "WHERE modify_date > GETDATE() - 8\n",
    "ORDER BY modify_date DESC, object_name;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findCrModObjinLast360ODS_WebApps.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findCrModObjinLast360ODS_WebApps.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findCrModObjinLast360ODS_WebApps.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:50\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=PPROD;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "  ,name AS object_name   \n",
    "  ,SCHEMA_NAME(schema_id) AS schema_name  \n",
    "  ,type_desc  \n",
    "  ,create_date  \n",
    "  ,modify_date  \n",
    "FROM sys.objects  \n",
    "WHERE modify_date > GETDATE() - 8\n",
    "ORDER BY modify_date DESC, object_name;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findCrModObjinLast360PPROD.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findCrModObjinLast360PPROD.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findCrModObjinLast360PPROD.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findCrModObjinLast360PPROD.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findCrModObjinLast360PPROD.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:51\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Predictive_Analytics;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    "  ,name AS object_name   \n",
    "  ,SCHEMA_NAME(schema_id) AS schema_name  \n",
    "  ,type_desc  \n",
    "  ,create_date  \n",
    "  ,modify_date  \n",
    "FROM sys.objects  \n",
    "WHERE modify_date > GETDATE() - 8\n",
    "ORDER BY modify_date DESC, object_name;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findCrModObjinLast360Predictive_Analytics.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findCrModObjinLast360Predictive_Analytics.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findCrModObjinLast360Predictive_Analytics.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findCrModObjinLast360Predictive_Analytics.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findCrModObjinLast360Predictive_Analytics.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(007) Capture and catalog all stored procedures (current) in the database(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:52\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=ApplicationData;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "       SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_TYPE, CREATED, LAST_ALTERED\n",
    " FROM [ApplicationData].INFORMATION_SCHEMA.ROUTINES\n",
    " WHERE ROUTINE_TYPE = 'PROCEDURE' \n",
    "   AND LEFT(ROUTINE_NAME, 3) NOT IN ('xp_', 'ms_')\n",
    " Order by LAST_ALTERED Desc;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\ProceduresApplicationData.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\ProceduresApplicationData.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\ProceduresApplicationData.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: ProceduresApplicationData.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: ProceduresApplicationData.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:54\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Assessment;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "       SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_TYPE, CREATED, LAST_ALTERED\n",
    "  FROM [Assessment].INFORMATION_SCHEMA.ROUTINES\n",
    " WHERE ROUTINE_TYPE = 'PROCEDURE' \n",
    "   AND LEFT(ROUTINE_NAME, 3) NOT IN ('xp_', 'ms_')\n",
    " Order by LAST_ALTERED Desc;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\ProceduresAssessment.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\ProceduresAssessment.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\ProceduresAssessment.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: ProceduresAssessment.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: ProceduresAssessment.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:55\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Control;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "       SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_TYPE, CREATED, LAST_ALTERED\n",
    "  FROM [Control].INFORMATION_SCHEMA.ROUTINES\n",
    " WHERE ROUTINE_TYPE = 'PROCEDURE' \n",
    "   AND LEFT(ROUTINE_NAME, 3) NOT IN ('xp_', 'ms_')\n",
    " Order by LAST_ALTERED Desc;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\ProceduresControl.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\ProceduresControl.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\ProceduresControl.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: ProceduresControl.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: ProceduresControl.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:56\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=DownstreamFeeds;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "       SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_TYPE, CREATED, LAST_ALTERED\n",
    "  FROM [DownstreamFeeds].INFORMATION_SCHEMA.ROUTINES\n",
    " WHERE ROUTINE_TYPE = 'PROCEDURE' \n",
    "   AND LEFT(ROUTINE_NAME, 3) NOT IN ('xp_', 'ms_')\n",
    " Order by LAST_ALTERED Desc;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\ProceduresDownstreamFeeds.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\ProceduresDownstreamFeeds.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\ProceduresDownstreamFeeds.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: ProceduresDownstreamFeeds.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: ProceduresDownstreamFeeds.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:58\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=DownstreamFeeds_V1.5;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "       SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_TYPE, CREATED, LAST_ALTERED\n",
    "  FROM [DownstreamFeeds_V1.5].INFORMATION_SCHEMA.ROUTINES\n",
    " WHERE ROUTINE_TYPE = 'PROCEDURE' \n",
    "   AND LEFT(ROUTINE_NAME, 3) NOT IN ('xp_', 'ms_')\n",
    " Order by LAST_ALTERED Desc;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\ProceduresDownstreamFeeds_V15.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\ProceduresDownstreamFeeds_V15.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\ProceduresDownstreamFeeds_V15.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: ProceduresDownstreamFeeds_V15.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: ProceduresDownstreamFeeds_V15.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:04:59\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GCPS_Operations;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "       SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_TYPE, CREATED, LAST_ALTERED\n",
    "  FROM [GCPS_Operations].INFORMATION_SCHEMA.ROUTINES\n",
    " WHERE ROUTINE_TYPE = 'PROCEDURE' \n",
    "   AND LEFT(ROUTINE_NAME, 3) NOT IN ('xp_', 'ms_')\n",
    " Order by LAST_ALTERED Desc;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\ProceduresGCPS_Operations.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\ProceduresGCPS_Operations.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\ProceduresGCPS_Operations.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: ProceduresGCPS_Operations.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: ProceduresGCPS_Operations.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:05:00\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Synergy_Temp;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "       SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_TYPE, CREATED, LAST_ALTERED\n",
    "  FROM [GSDR_Synergy_Temp].INFORMATION_SCHEMA.ROUTINES\n",
    " WHERE ROUTINE_TYPE = 'PROCEDURE' \n",
    "   AND LEFT(ROUTINE_NAME, 3) NOT IN ('xp_', 'ms_')\n",
    " Order by LAST_ALTERED Desc;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\ProceduresGSDR_Synergy_Temp.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\ProceduresGSDR_Synergy_Temp.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\ProceduresGSDR_Synergy_Temp.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: ProceduresGSDR_Synergy_Temp.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: ProceduresGSDR_Synergy_Temp.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:05:01\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Synergy;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "       SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_TYPE, CREATED, LAST_ALTERED\n",
    "  FROM [GSDR_Synergy].INFORMATION_SCHEMA.ROUTINES\n",
    " WHERE ROUTINE_TYPE = 'PROCEDURE' \n",
    "   AND LEFT(ROUTINE_NAME, 3) NOT IN ('xp_', 'ms_')\n",
    " Order by LAST_ALTERED Desc;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\ProceduresGSDR_Synergy.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\ProceduresGSDR_Synergy.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\ProceduresGSDR_Synergy.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: ProceduresGSDR_Synergy.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: ProceduresGSDR_Synergy.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:05:03\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR_Temp;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "       SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_TYPE, CREATED, LAST_ALTERED\n",
    "  FROM [GSDR_Temp].INFORMATION_SCHEMA.ROUTINES\n",
    " WHERE ROUTINE_TYPE = 'PROCEDURE' \n",
    "   AND LEFT(ROUTINE_NAME, 3) NOT IN ('xp_', 'ms_')\n",
    " Order by LAST_ALTERED Desc;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\ProceduresGSDR_Temp.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\ProceduresGSDR_Temp.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\ProceduresGSDR_Temp.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: ProceduresGSDR_Temp.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: ProceduresGSDR_Temp.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:05:04\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "       SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_TYPE, CREATED, LAST_ALTERED\n",
    "  FROM [GSDR].INFORMATION_SCHEMA.ROUTINES\n",
    " WHERE ROUTINE_TYPE = 'PROCEDURE' \n",
    "   AND LEFT(ROUTINE_NAME, 3) NOT IN ('xp_', 'ms_')\n",
    " Order by LAST_ALTERED Desc;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\ProceduresGSDR.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\ProceduresGSDR.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\ProceduresGSDR.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: ProceduresGSDR.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: ProceduresGSDR.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:05:06\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=ODS_WebApps;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "       SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_TYPE, CREATED, LAST_ALTERED\n",
    "  FROM [ODS_WebApps].INFORMATION_SCHEMA.ROUTINES\n",
    " WHERE ROUTINE_TYPE = 'PROCEDURE' \n",
    "   AND LEFT(ROUTINE_NAME, 3) NOT IN ('xp_', 'ms_')\n",
    " Order by LAST_ALTERED Desc;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\ProceduresODS_WebApps.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\ProceduresODS_WebApps.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\ProceduresODS_WebApps.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: ProceduresODS_WebApps.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: ProceduresODS_WebApps.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:05:07\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=PPROD;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "       SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_TYPE, CREATED, LAST_ALTERED\n",
    "  FROM [PPROD].INFORMATION_SCHEMA.ROUTINES\n",
    " WHERE ROUTINE_TYPE = 'PROCEDURE' \n",
    "   AND LEFT(ROUTINE_NAME, 3) NOT IN ('xp_', 'ms_')\n",
    " Order by LAST_ALTERED Desc;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\ProceduresPPROD.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\ProceduresPPROD.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\ProceduresPPROD.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: ProceduresPPROD.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: ProceduresPPROD.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:05:08\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Predictive_Analytics;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "       SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_TYPE, CREATED, LAST_ALTERED\n",
    "  FROM [Predictive_Analytics].INFORMATION_SCHEMA.ROUTINES\n",
    " WHERE ROUTINE_TYPE = 'PROCEDURE' \n",
    "   AND LEFT(ROUTINE_NAME, 3) NOT IN ('xp_', 'ms_')\n",
    " Order by LAST_ALTERED Desc;  \n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\ProceduresPredictive_Analytics.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\ProceduresPredictive_Analytics.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\ProceduresPredictive_Analytics.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: ProceduresPredictive_Analytics.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: ProceduresPredictive_Analytics.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(008) Find and collect all registered DTSX packages in the database (validate against TFS code repository) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:05:09\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Master;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT CONVERT(char(8), GetDate(),112) as TodaysDate\n",
    ",  J.name AS JobName \n",
    ",  S.step_id AS StepNbr\n",
    ",  S.step_name AS StepName\n",
    ",  LEFT(REPLACE(REPLACE(S.command, '/FILE \"',''),'\\\"',''), CHARINDEX('.dtsx', REPLACE(REPLACE(S.command, '/FILE \"',''),'\\\"',''))+4) AS SSISPackagePath\n",
    "FROM  msdb.dbo.sysjobs AS J\n",
    "INNER JOIN msdb.dbo.sysjobsteps AS S \n",
    "ON  J.job_id = S.job_id\n",
    "WHERE J.enabled = 1 \n",
    "AND  S.subsystem = 'SSIS'\n",
    "ORDER BY J.name \n",
    ",  S.step_id;\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findtopJobNameStepNum_dtsx.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findtopJobNameStepNum_dtsx.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findtopJobNameStepNum_dtsx.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findtopJobNameStepNum_dtsx.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findtopJobNameStepNum_dtsx.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(009) Find all the current SSMS job failures and review for changes to the system for EDP migration effort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:05:11\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=Master;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "# The furthest back SQL Server will retain errata on the job runs is day, 120\n",
    "# change the declare statement back if the results you are seeking are not in the retained file records\n",
    "# looking at run status = 1 (success) results in nothing tangible for the migration effort \n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "declare @date datetime = dateadd(hour, 12, datediff(day, 7, getdate()));\n",
    "\n",
    "/* PRODODSSQL */\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "select \n",
    "    [sJobHistory].[server]\n",
    "  , [sJOB].[name] as          [JobName]\n",
    "  , [sJobHistory].step_id\n",
    "  , [sJobHistory].step_name\n",
    "  , case\n",
    "\t\twhen [sJobHistory].run_status = 1 then 'Succeeded'\n",
    "\t\twhen [sJobHistory].run_status = 0 then 'Failed'\n",
    "\t\telse convert(nvarchar(10),[sJobHistory].run_status)\n",
    "\tend\trun_status \n",
    "  , sJobHistory.[message]\n",
    "  , [msdb].[dbo].agent_datetime(run_date,run_time) runtime\n",
    "  , [sJobHistory].run_duration\n",
    "  , [sJOB].[description] as   [JobDescription]\n",
    "\n",
    "from [msdb].[dbo].[sysjobs]\t\t\t\t\t\tas [sJOB]\n",
    "join [msdb].[dbo].[sysjobhistory]\t\t\t\tas [sJobHistory]\ton [sjob].job_id\t\t\t\t\t= sJobHistory.job_id\n",
    "left join [msdb].[sys].[servers]\t\t\t\tas [sSVR]\t\t\ton [sJOB].[originating_server_id]\t= [sSVR].[server_id]\n",
    "left join [msdb].[dbo].[syscategories]\t\t\tas [sCAT]\t\t\ton [sJOB].[category_id]\t\t\t\t= [sCAT].[category_id]\n",
    "left join [msdb].[dbo].[sysjobsteps]\t\t\tas [sJSTP]\t\t\ton [sJOB].[job_id]\t\t\t\t\t= [sJSTP].[job_id]\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tand [sJOB].[start_step_id]\t\t\t= [sJSTP].[step_id]\n",
    "left join [msdb].[sys].[database_principals]\tas [sDBP]\t\t\ton [sJOB].[owner_sid]\t\t\t\t= [sDBP].[sid]\n",
    "left join [msdb].[dbo].[sysjobschedules]\t\tas [sJOBSCH]\t\ton [sJOB].[job_id]\t\t\t\t\t= [sJOBSCH].[job_id]\n",
    "left join [msdb].[dbo].[sysschedules]\t\t\tas [sSCH]\t\t\ton [sJOBSCH].[schedule_id]\t\t\t= [sSCH].[schedule_id]\n",
    "\n",
    "where 1=1\n",
    "\n",
    "and run_status = 0\n",
    "\n",
    "and [msdb].[dbo].agent_datetime(run_date,run_time) >= @date\n",
    "\n",
    "\n",
    "/* PRODSISSQL */\n",
    "union all\n",
    "select \n",
    "    [sJobHistory].[server]\n",
    "  , [sJOB].[name] as          [JobName]\n",
    "  , [sJobHistory].step_id\n",
    "  , [sJobHistory].step_name\n",
    "  , case\n",
    "\t\twhen [sJobHistory].run_status = 1 then 'Succeeded'\n",
    "\t\twhen [sJobHistory].run_status = 0 then 'Failed'\n",
    "\t\telse convert(nvarchar(10),[sJobHistory].run_status)\n",
    "\tend\trun_status \n",
    "  , sJobHistory.[message]\n",
    "  , [msdb].[dbo].agent_datetime(run_date,run_time) runtime\n",
    "  , [sJobHistory].run_duration\n",
    "  , [sJOB].[description] as   [JobDescription]\n",
    "\n",
    "from prodsissql.[msdb].[dbo].[sysjobs]\t\t\t\t\t\tas [sJOB]\n",
    "join prodsissql.[msdb].[dbo].[sysjobhistory]\t\t\t\tas [sJobHistory]\ton [sjob].job_id\t\t\t\t\t= sJobHistory.job_id\n",
    "left join prodsissql.[msdb].[sys].[servers]\t\t\t\t\tas [sSVR]\t\t\ton [sJOB].[originating_server_id]\t= [sSVR].[server_id]\n",
    "left join prodsissql.[msdb].[dbo].[syscategories]\t\t\tas [sCAT]\t\t\ton [sJOB].[category_id]\t\t\t\t= [sCAT].[category_id]\n",
    "left join prodsissql.[msdb].[dbo].[sysjobsteps]\t\t\t\tas [sJSTP]\t\t\ton [sJOB].[job_id]\t\t\t\t\t= [sJSTP].[job_id]\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tand [sJOB].[start_step_id]\t\t\t= [sJSTP].[step_id]\n",
    "left join prodsissql.[msdb].[sys].[database_principals]\t\tas [sDBP]\t\t\ton [sJOB].[owner_sid]\t\t\t\t= [sDBP].[sid]\n",
    "left join prodsissql.[msdb].[dbo].[sysjobschedules]\t\t\tas [sJOBSCH]\t\ton [sJOB].[job_id]\t\t\t\t\t= [sJOBSCH].[job_id]\n",
    "left join prodsissql.[msdb].[dbo].[sysschedules]\t\t\tas [sSCH]\t\t\ton [sJOBSCH].[schedule_id]\t\t\t= [sSCH].[schedule_id]\n",
    "\n",
    "where 1=1\n",
    "\n",
    "and run_status = 0\n",
    "and [msdb].[dbo].agent_datetime(run_date,run_time) >= @date\n",
    "\n",
    "order by \n",
    "runtime desc\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findSSMSjobFailures.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findSSMSjobFailures.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findSSMSjobFailures.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "    \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findSSMSjobFailures.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findSSMSjobFailures.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(010) Collection of table differences compared to partitions found (looking for uniqueness) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:05:12\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=PRODODSSQL;'\n",
    "                      'Database=GSDR;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "SELECT CONVERT(char(8), GetDate(),112) as TodaysDate,\n",
    "c.name as SchemaName, t.name as TableName, t.object_id as TableObjectID, s.object_id as PartObjectID, s.row_count as RecordCount\n",
    "from sys.tables t,\n",
    "sys.dm_db_partition_stats s,\n",
    "sys.schemas c\n",
    "where \n",
    "t.schema_id = c.schema_id\n",
    "AND t.object_id = s.object_id\n",
    "AND t.type_desc = 'USER_TABLE'\n",
    "AND t.name not like '%dss%'\n",
    "AND s.index_id IN (0,1)\n",
    "ORDER BY 2\n",
    "\n",
    "                              '''\n",
    "                              ,conn) # here, the 'conn' is the variable that contains your database connection information from above\n",
    "\n",
    "df = pd.DataFrame(sql_query)\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\A\\findGSDRtablePartitioningDiffObjectsIDS.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\B\\findGSDRtablePartitioningDiffObjectsIDS.csv', 'a') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "with open(r'C:\\Users\\e201873842\\Documents\\JupyterAnacondaPythonNotebooks\\Daily\\local\\T\\findGSDRtablePartitioningDiffObjectsIDS.csv', 'w') as f:\n",
    "    df.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: findGSDRtablePartitioningDiffObjectsIDS.csv file written - continue program ***\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "time.sleep(1) # Sleep for 1 seconds\n",
    "print(' *** Note: findGSDRtablePartitioningDiffObjectsIDS.csv file written - continue program ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete:  2021-05-05 07:05:13\n",
      " *** Note: ****.csv files written - this program has completed successfully - review output ***\n"
     ]
    }
   ],
   "source": [
    "now01 = datetime.datetime.now()\n",
    "print('Processing Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print(' *** Note: ****.csv files written - this program has completed successfully - review output ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
