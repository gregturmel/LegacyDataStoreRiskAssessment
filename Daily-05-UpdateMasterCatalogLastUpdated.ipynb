{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ProgramName: Daily-05-UpdateMasterCatalog-Db-Sc-Tbl-LastUpdated\n",
    "#Purpose: Weekly Update Master Catalog - Routine Maintenance-LastUpdated, DatabaseName, SchemaName, TableName\n",
    "#Author:  Greg Turmel, Director, Data Governance \n",
    "#Date:    2020.08.30 - 2021.06.30\n",
    "#Errata:  0.1 Improvements can be made to script using for/looping through the metadata captured\n",
    "\n",
    "import os, sys, argparse, csv, pyodbc, sql, time, datetime\n",
    "import sqlalchemy as db\n",
    "import errno, pathlib2\n",
    "\n",
    "from dotenv import load_dotenv # add this line\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "\n",
    "load_dotenv() # add this line\n",
    "user = os.getenv('MySQLeUser')\n",
    "password = os.getenv('MySQLeUserPass')\n",
    "host = os.getenv('MySQLeHOST')\n",
    "db = os.getenv('MySQLeDB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent Directory is:  C:\\Users\\e201873842\\Documents\\Py\n",
      "Directory: Daily >>>>> Note ---- this folder already exists <<<<<\n",
      "Directory: C:\\Users\\e201873842\\Documents\\Py\\Daily\\Master\\Process >>>>> Note ---- this folder already exists <<<<<\n",
      "Directory: C:\\Users\\e201873842\\Documents\\Py\\Daily\\Master\\Reports >>>>> Note ---- this folder already exists <<<<<\n",
      "Directory: C:\\Users\\e201873842\\Documents\\Py\\Daily\\Master\\sql >>>>> Note ---- this folder already exists <<<<<\n",
      "Central Config Directory: C:\\Users\\e201873842\\Documents\\Py\\Daily\\config >>>>> Note ---- this folder already exists <<<<<\n"
     ]
    }
   ],
   "source": [
    "# This segment builds the appropriatte file system structure as a variable driven exercise\n",
    "# Take time to set your 'eeeeeeeeee' number as variable 'pn' below \n",
    "# and set the program directory variable called 'programDirectory' before running\n",
    "# ===================================================================================================================\n",
    "pn = r'eeeeeeeeee'            #This represents the windows system employee login folder - IBM team uses a 9 number\n",
    "# ===================================================================================================================\n",
    "\n",
    "programDirectory = 'Daily' # Update this variable to wherever you want the program subfolder/files to be located \n",
    "un = r'C:\\Users'\n",
    "cn = r'Documents\\Py'\n",
    "an = r'Master\\Process'\n",
    "bn = r'Master\\Reports'\n",
    "\n",
    "sn = r'Master\\sql'\n",
    "tn = r'config'\n",
    "\n",
    "#Set a parent directory\n",
    "parentDirectory = \"{}\\{}\\{}\".format(un,pn,cn)\n",
    "print('Parent Directory is: ', parentDirectory)\n",
    "mode = 0o666\n",
    "\n",
    "#Set path location for working with local file(s)\n",
    "path = os.path.join(parentDirectory, programDirectory,)\n",
    "pathMP = os.path.join(parentDirectory, programDirectory, an)\n",
    "pathMR = os.path.join(parentDirectory, programDirectory, bn)\n",
    "pathMS = os.path.join(parentDirectory, programDirectory, sn)\n",
    "pathMT = os.path.join(parentDirectory, programDirectory, tn)\n",
    "\n",
    "procpath = pathMP\n",
    "csvpath = pathMR\n",
    "sqlpath = pathMS\n",
    "configpath = pathMT\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path, mode)\n",
    "        print('Program Directory subfolder has been created: ', programDirectory)\n",
    "    else:\n",
    "        print('Directory:', programDirectory, '>>>>> Note ---- this folder already exists <<<<<')\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(pathMP):\n",
    "        os.makedirs(pathMP, mode)\n",
    "        print('Program Directory subfolder has been created: ', pathMP)\n",
    "    else:\n",
    "        print('Directory:', pathMP, '>>>>> Note ---- this folder already exists <<<<<')\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(pathMR):\n",
    "        os.makedirs(pathMR, mode)\n",
    "        print('Program Directory subfolder has been created: ', pathMR)\n",
    "    else:\n",
    "        print('Directory:', pathMR, '>>>>> Note ---- this folder already exists <<<<<')\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(pathMS):\n",
    "        os.makedirs(pathMS, mode)\n",
    "        print('Program Directory subfolder has been created: ', pathMS)\n",
    "    else:\n",
    "        print('Directory:', pathMS, '>>>>> Note ---- this folder already exists <<<<<')\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(pathMT):\n",
    "        os.makedirs(pathMT, mode)\n",
    "        print('Program Directory subfolder has been created: ', pathMT)\n",
    "    else:\n",
    "        print('Central Config Directory:', pathMT, '>>>>> Note ---- this folder already exists <<<<<')\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Production Catalog collected:  ApplicationData 2021-06-14 07:50:50\n",
      "Production Catalog collected:  Assessment 2021-06-14 07:50:50\n",
      "Production Catalog collected:  Control 2021-06-14 07:50:50\n",
      "Production Catalog collected:  DownstreamFeeds 2021-06-14 07:50:50\n",
      "Production Catalog collected:  DownstreamFeeds_V1.5 2021-06-14 07:50:50\n",
      "Production Catalog collected:  GCPS_Operations 2021-06-14 07:50:50\n",
      "Production Catalog collected:  GSDR 2021-06-14 07:50:50\n",
      "Production Catalog collected:  GSDR_Synergy 2021-06-14 07:50:50\n",
      "Production Catalog collected:  GSDR_Synergy_Temp 2021-06-14 07:50:50\n",
      "Production Catalog collected:  GSDR_Temp 2021-06-14 07:50:50\n",
      "Production Catalog collected:  ODS_WebApps 2021-06-14 07:50:50\n",
      "Production Catalog collected:  PPROD 2021-06-14 07:50:50\n",
      "Production Catalog collected:  Predictive_Analytics 2021-06-14 07:50:50\n",
      "Production System Catalog Data Collection Process is now Complete:  2021-06-14 07:50:52\n"
     ]
    }
   ],
   "source": [
    "#C:\\Users\\eeeeeeeeee\\Documents\\Py\\Weekly\\Master\\\n",
    "\n",
    "with open(os.path.join(pathMR, 'upDate.csv'), 'w') as f:\n",
    "    pass\n",
    "            \n",
    "dbList = ['ApplicationData','Assessment','Control','DownstreamFeeds','DownstreamFeeds_V1.5','GCPS_Operations','GSDR','GSDR_Synergy','GSDR_Synergy_Temp','GSDR_Temp','ODS_WebApps','PPROD','Predictive_Analytics']\n",
    "\n",
    "for x in dbList:\n",
    "    try:\n",
    "        conn = pyodbc.connect('Server=PRODODSSQL;'\n",
    "                              'Trusted_Connection=yes;'\n",
    "                              'DRIVER={{SQL Server}};'\n",
    "                              'Database={0}'.format(x))\n",
    "\n",
    "        sql_query = pd.read_sql_query(''' \n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "select DISTINCT CONVERT(char(8), GetDate(),112) as TodaysDate, DB_Name() AS DatabaseName, s.name as SchemaName, OBJECT_NAME(o.OBJECT_ID) AS TableName, t.modify_date AS LastUpdated\n",
    "FROM\n",
    "SYS.objects o JOIN SYS.schemas s \n",
    "   ON o.schema_id=s.schema_id\n",
    "        JOIN sys.dm_db_partition_stats p\n",
    "   ON o.object_id=p.object_id\n",
    "        JOIN sys.tables t\n",
    "   ON o.modify_date = t.modify_date\n",
    "WHERE o.type LIKE 'U'\n",
    "---AND p.row_count > 0\n",
    "ORDER BY TableName, LastUpdated\n",
    "                              '''\n",
    "                              ,conn) #\n",
    "\n",
    "        dfp = pd.DataFrame(sql_query)\n",
    "        with open(os.path.join(pathMR, 'upDate.csv'), 'a') as f:\n",
    "            dfp.to_csv(f, header=f.tell()==0, index=False, line_terminator='\\n')\n",
    "\n",
    "        conn.close()\n",
    "    except:\n",
    "        continue\n",
    "    finally:\n",
    "        print('Production Catalog collected: ', x, now01.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        continue\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Production System Catalog Data Collection Process is now Complete: ', now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note:  database table Greg.dbo.MasterPRODCatalog cleaned out - step complete ***\n"
     ]
    }
   ],
   "source": [
    "#Set up table - remove previous records \n",
    "#Comment out if you want to track changes in table by the TodaysDate column\n",
    "#TypeError: 'NoneType' object is not iterable --- Solution is: SET ANSI_WARNINGS OFF\n",
    "\n",
    "#Connect to SQL Server\n",
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=DEVODSSQL;'\n",
    "                      'Database=Greg;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(''' \n",
    "SET NOCOUNT ON\n",
    "SET ANSI_WARNINGS OFF\n",
    "IF EXISTS(SELECT 1 FROM dbo.MasterPRODCatalog)\n",
    "BEGIN\n",
    "   DELETE FROM Greg.dbo.MasterPRODCatalog WHERE [LastUpdated] > '19000101';\n",
    "END\n",
    "'''\n",
    ",)\n",
    "conn.commit()\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(' *** Note:  database table Greg.dbo.MasterPRODCatalog cleaned out - step complete ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: csv file written to database table complete ***\n",
      "Processing Step to LOAD MasterCatalog Table is now Complete:  2021-06-14 07:51:03\n",
      " *** Note: count from table data loaded is: ***        \n",
      "0  4310\n"
     ]
    }
   ],
   "source": [
    "# Import CSV\n",
    "data = pd.read_csv(\"{}/{}\".format(pathMR, 'upDate.csv'))   \n",
    "df = pd.DataFrame(data, columns= ['TodaysDate','DatabaseName','SchemaName','TableName','LastUpdated'])\n",
    "\n",
    "# Connect to SQL Server\n",
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=DEVODSSQL;'\n",
    "                      'Database=Greg;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Insert DataFrame to Table\n",
    "for row in df.itertuples():\n",
    "    cursor.execute('''\n",
    "                INSERT INTO Greg.dbo.MasterPRODCatalog (TodaysDate,DatabaseName,SchemaName,TableName,LastUpdated)\n",
    "                VALUES (?,?,?,?,?);\n",
    "                ''',\n",
    "                row.TodaysDate,\n",
    "                row.DatabaseName,\n",
    "                row.SchemaName,\n",
    "                row.TableName,\n",
    "                row.LastUpdated\n",
    "                )\n",
    "conn.commit()\n",
    "\n",
    "cursor.close()\n",
    "\n",
    "print(' *** Note: csv file written to database table complete ***')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select count(*) FROM Greg.dbo.MasterPRODCatalog WHERE [TodaysDate] LIKE convert(varchar, getdate(), 112);\n",
    "                              '''\n",
    "                              ,conn) # \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print('Processing Step to LOAD MasterCatalog Table is now Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print(' *** Note: count from table data loaded is: ***', sql_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note: csv file written to database table complete ***\n",
      " *** LOAD MasterCatalogTracking Table is now Complete:  2021-06-14 07:51:13\n",
      " *** Note: count from table data loaded is: ***        \n",
      "0  4310\n"
     ]
    }
   ],
   "source": [
    "# Import CSV\n",
    "data = pd.read_csv(\"{}/{}\".format(pathMR, 'upDate.csv'))   \n",
    "df = pd.DataFrame(data, columns= ['TodaysDate','DatabaseName','SchemaName','TableName','LastUpdated'])\n",
    "\n",
    "# Connect to SQL Server\n",
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=DEVODSSQL;'\n",
    "                      'Database=Greg;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# READ ME\n",
    "# Insert DataFrame to Master Tracking Table - Analysis to determine systematic changes overwritten by the next step\n",
    "# By using this tracking table the IBM team can monitor the gross total changes month by month that are lost by the\n",
    "# system catalog being updated daily and loss of that dynmic change can impact decisions on activites for migration\n",
    "# DO NOT look at this STEP as a duplicate of the one below. This one TRACKS and the next one updates the Master with\n",
    "# New changes found\n",
    "\n",
    "for row in df.itertuples():\n",
    "    cursor.execute('''\n",
    "                INSERT INTO Greg.dbo.MasterPRODCatalogTracking (TodaysDate,DatabaseName,SchemaName,TableName,LastUpdated)\n",
    "                VALUES (?,?,?,?,?);\n",
    "                ''',\n",
    "                row.TodaysDate,\n",
    "                row.DatabaseName,\n",
    "                row.SchemaName,\n",
    "                row.TableName,\n",
    "                row.LastUpdated\n",
    "                )\n",
    "conn.commit()\n",
    "\n",
    "cursor.close()\n",
    "\n",
    "print(' *** Note: csv file written to database table complete ***')\n",
    "\n",
    "sql_query = pd.read_sql_query(''' \n",
    "select count(*) FROM Greg.dbo.MasterPRODCatalogTracking WHERE [TodaysDate] LIKE convert(varchar, getdate(), 112);\n",
    "                              '''\n",
    "                              ,conn) # \n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print(' *** LOAD MasterCatalogTracking Table is now Complete: ',now01.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print(' *** Note: count from table data loaded is: ***', sql_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Note:  database table Greg.dbo.Master updated:  2021-06-14 07:51:13\n"
     ]
    }
   ],
   "source": [
    "#Connect to SQL Server\n",
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=DEVODSSQL;'\n",
    "                      'Database=Greg;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "cursor = conn.cursor()\n",
    "#If Exists, Crear out any data from the tempGreg table if last used \n",
    "cursor.execute(''' \n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED\n",
    "SET NOCOUNT ON\n",
    "SET ANSI_WARNINGS OFF\n",
    "IF OBJECT_ID('tempdb..#tempGreg') IS NOT NULL \n",
    "BEGIN \n",
    "    DROP TABLE #tempGreg\n",
    "END \n",
    ";\n",
    "'''\n",
    ",)\n",
    "conn.commit()\n",
    "\n",
    "#Update the Master table with any tables that have been updated by the ODS programming team(s) and or software processes\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(''' \n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED\n",
    "SET NOCOUNT ON\n",
    "SET ANSI_WARNINGS OFF\n",
    "MERGE [Greg].[dbo].[Master] T\n",
    "USING dbo.[MasterPRODCatalog] S ON T.DatabaseName=S.DatabaseName AND T.SchemaName=S.SchemaName AND T.TableName=S.TableName\n",
    "WHEN MATCHED THEN\n",
    "UPDATE SET LastUpdated=S.LastUpdated\n",
    "WHEN NOT MATCHED BY TARGET THEN \n",
    "INSERT (DatabaseName,SchemaName,TableName,LastUpdated)\n",
    "VALUES (S.DatabaseName,S.SchemaName,S.TableName,S.LastUpdated);\n",
    "'''\n",
    ",)\n",
    "conn.commit()\n",
    "\n",
    "conn.close()\n",
    "\n",
    "now01 = datetime.datetime.now()\n",
    "print(' *** Note:  database table Greg.dbo.Master updated: ', now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routine Maintenance Job - Last Updated Field updated - Process Complete:  2021-06-14 07:51:13\n"
     ]
    }
   ],
   "source": [
    "now01 = datetime.datetime.now()\n",
    "print('Routine Maintenance Job - Last Updated Field updated - Process Complete: ', now01.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
